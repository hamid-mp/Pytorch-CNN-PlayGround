{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamid-mp/Pytorch-CNN-PlayGround/blob/main/gold_price_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))\n",
        "\n",
        "configure_plotly_browser_state()\n"
      ],
      "metadata": {
        "id": "vgmrcPtnhldk",
        "colab": {
          "resources": {
            "http://localhost:8080/static/components/requirejs/require.js": {
              "data": "/** vim: et:ts=4:sw=4:sts=4
 * @license RequireJS 2.2.0 Copyright jQuery Foundation and other contributors.
 * Released under MIT license, http://github.com/requirejs/requirejs/LICENSE
 */
//Not using strict: uneven strict support in browsers, #392, and causes
//problems with requirejs.exec()/transpiler plugins that may not be strict.
/*jslint regexp: true, nomen: true, sloppy: true */
/*global window, navigator, document, importScripts, setTimeout, opera */

var requirejs, require, define;
(function (global) {
    var req, s, head, baseElement, dataMain, src,
        interactiveScript, currentlyAddingScript, mainScript, subPath,
        version = '2.2.0',
        commentRegExp = /(\/\*([\s\S]*?)\*\/|([^:]|^)\/\/(.*)$)/mg,
        cjsRequireRegExp = /[^.]\s*require\s*\(\s*["']([^'"\s]+)["']\s*\)/g,
        jsSuffixRegExp = /\.js$/,
        currDirRegExp = /^\.\//,
        op = Object.prototype,
        ostring = op.toString,
        hasOwn = op.hasOwnProperty,
        isBrowser = !!(typeof window !== 'undefined' && typeof navigator !== 'undefined' && window.document),
        isWebWorker = !isBrowser && typeof importScripts !== 'undefined',
        //PS3 indicates loaded and complete, but need to wait for complete
        //specifically. Sequence is 'loading', 'loaded', execution,
        // then 'complete'. The UA check is unfortunate, but not sure how
        //to feature test w/o causing perf issues.
        readyRegExp = isBrowser && navigator.platform === 'PLAYSTATION 3' ?
                      /^complete$/ : /^(complete|loaded)$/,
        defContextName = '_',
        //Oh the tragedy, detecting opera. See the usage of isOpera for reason.
        isOpera = typeof opera !== 'undefined' && opera.toString() === '[object Opera]',
        contexts = {},
        cfg = {},
        globalDefQueue = [],
        useInteractive = false;

    //Could match something like ')//comment', do not lose the prefix to comment.
    function commentReplace(match, multi, multiText, singlePrefix) {
        return singlePrefix || '';
    }

    function isFunction(it) {
        return ostring.call(it) === '[object Function]';
    }

    function isArray(it) {
        return ostring.call(it) === '[object Array]';
    }

    /**
     * Helper function for iterating over an array. If the func returns
     * a true value, it will break out of the loop.
     */
    function each(ary, func) {
        if (ary) {
            var i;
            for (i = 0; i < ary.length; i += 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    /**
     * Helper function for iterating over an array backwards. If the func
     * returns a true value, it will break out of the loop.
     */
    function eachReverse(ary, func) {
        if (ary) {
            var i;
            for (i = ary.length - 1; i > -1; i -= 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    function hasProp(obj, prop) {
        return hasOwn.call(obj, prop);
    }

    function getOwn(obj, prop) {
        return hasProp(obj, prop) && obj[prop];
    }

    /**
     * Cycles over properties in an object and calls a function for each
     * property value. If the function returns a truthy value, then the
     * iteration is stopped.
     */
    function eachProp(obj, func) {
        var prop;
        for (prop in obj) {
            if (hasProp(obj, prop)) {
                if (func(obj[prop], prop)) {
                    break;
                }
            }
        }
    }

    /**
     * Simple function to mix in properties from source into target,
     * but only if target does not already have a property of the same name.
     */
    function mixin(target, source, force, deepStringMixin) {
        if (source) {
            eachProp(source, function (value, prop) {
                if (force || !hasProp(target, prop)) {
                    if (deepStringMixin && typeof value === 'object' && value &&
                        !isArray(value) && !isFunction(value) &&
                        !(value instanceof RegExp)) {

                        if (!target[prop]) {
                            target[prop] = {};
                        }
                        mixin(target[prop], value, force, deepStringMixin);
                    } else {
                        target[prop] = value;
                    }
                }
            });
        }
        return target;
    }

    //Similar to Function.prototype.bind, but the 'this' object is specified
    //first, since it is easier to read/figure out what 'this' will be.
    function bind(obj, fn) {
        return function () {
            return fn.apply(obj, arguments);
        };
    }

    function scripts() {
        return document.getElementsByTagName('script');
    }

    function defaultOnError(err) {
        throw err;
    }

    //Allow getting a global that is expressed in
    //dot notation, like 'a.b.c'.
    function getGlobal(value) {
        if (!value) {
            return value;
        }
        var g = global;
        each(value.split('.'), function (part) {
            g = g[part];
        });
        return g;
    }

    /**
     * Constructs an error with a pointer to an URL with more information.
     * @param {String} id the error ID that maps to an ID on a web page.
     * @param {String} message human readable error.
     * @param {Error} [err] the original error, if there is one.
     *
     * @returns {Error}
     */
    function makeError(id, msg, err, requireModules) {
        var e = new Error(msg + '\nhttp://requirejs.org/docs/errors.html#' + id);
        e.requireType = id;
        e.requireModules = requireModules;
        if (err) {
            e.originalError = err;
        }
        return e;
    }

    if (typeof define !== 'undefined') {
        //If a define is already in play via another AMD loader,
        //do not overwrite.
        return;
    }

    if (typeof requirejs !== 'undefined') {
        if (isFunction(requirejs)) {
            //Do not overwrite an existing requirejs instance.
            return;
        }
        cfg = requirejs;
        requirejs = undefined;
    }

    //Allow for a require config object
    if (typeof require !== 'undefined' && !isFunction(require)) {
        //assume it is a config object.
        cfg = require;
        require = undefined;
    }

    function newContext(contextName) {
        var inCheckLoaded, Module, context, handlers,
            checkLoadedTimeoutId,
            config = {
                //Defaults. Do not set a default for map
                //config to speed up normalize(), which
                //will run faster if there is no default.
                waitSeconds: 7,
                baseUrl: './',
                paths: {},
                bundles: {},
                pkgs: {},
                shim: {},
                config: {}
            },
            registry = {},
            //registry of just enabled modules, to speed
            //cycle breaking code when lots of modules
            //are registered, but not activated.
            enabledRegistry = {},
            undefEvents = {},
            defQueue = [],
            defined = {},
            urlFetched = {},
            bundlesMap = {},
            requireCounter = 1,
            unnormalizedCounter = 1;

        /**
         * Trims the . and .. from an array of path segments.
         * It will keep a leading path segment if a .. will become
         * the first path segment, to help with module name lookups,
         * which act like paths, but can be remapped. But the end result,
         * all paths that use this function should look normalized.
         * NOTE: this method MODIFIES the input array.
         * @param {Array} ary the array of path segments.
         */
        function trimDots(ary) {
            var i, part;
            for (i = 0; i < ary.length; i++) {
                part = ary[i];
                if (part === '.') {
                    ary.splice(i, 1);
                    i -= 1;
                } else if (part === '..') {
                    // If at the start, or previous value is still ..,
                    // keep them so that when converted to a path it may
                    // still work when converted to a path, even though
                    // as an ID it is less than ideal. In larger point
                    // releases, may be better to just kick out an error.
                    if (i === 0 || (i === 1 && ary[2] === '..') || ary[i - 1] === '..') {
                        continue;
                    } else if (i > 0) {
                        ary.splice(i - 1, 2);
                        i -= 2;
                    }
                }
            }
        }

        /**
         * Given a relative module name, like ./something, normalize it to
         * a real name that can be mapped to a path.
         * @param {String} name the relative name
         * @param {String} baseName a real name that the name arg is relative
         * to.
         * @param {Boolean} applyMap apply the map config to the value. Should
         * only be done if this normalization is for a dependency ID.
         * @returns {String} normalized name
         */
        function normalize(name, baseName, applyMap) {
            var pkgMain, mapValue, nameParts, i, j, nameSegment, lastIndex,
                foundMap, foundI, foundStarMap, starI, normalizedBaseParts,
                baseParts = (baseName && baseName.split('/')),
                map = config.map,
                starMap = map && map['*'];

            //Adjust any relative paths.
            if (name) {
                name = name.split('/');
                lastIndex = name.length - 1;

                // If wanting node ID compatibility, strip .js from end
                // of IDs. Have to do this here, and not in nameToUrl
                // because node allows either .js or non .js to map
                // to same file.
                if (config.nodeIdCompat && jsSuffixRegExp.test(name[lastIndex])) {
                    name[lastIndex] = name[lastIndex].replace(jsSuffixRegExp, '');
                }

                // Starts with a '.' so need the baseName
                if (name[0].charAt(0) === '.' && baseParts) {
                    //Convert baseName to array, and lop off the last part,
                    //so that . matches that 'directory' and not name of the baseName's
                    //module. For instance, baseName of 'one/two/three', maps to
                    //'one/two/three.js', but we want the directory, 'one/two' for
                    //this normalization.
                    normalizedBaseParts = baseParts.slice(0, baseParts.length - 1);
                    name = normalizedBaseParts.concat(name);
                }

                trimDots(name);
                name = name.join('/');
            }

            //Apply map config if available.
            if (applyMap && map && (baseParts || starMap)) {
                nameParts = name.split('/');

                outerLoop: for (i = nameParts.length; i > 0; i -= 1) {
                    nameSegment = nameParts.slice(0, i).join('/');

                    if (baseParts) {
                        //Find the longest baseName segment match in the config.
                        //So, do joins on the biggest to smallest lengths of baseParts.
                        for (j = baseParts.length; j > 0; j -= 1) {
                            mapValue = getOwn(map, baseParts.slice(0, j).join('/'));

                            //baseName segment has config, find if it has one for
                            //this name.
                            if (mapValue) {
                                mapValue = getOwn(mapValue, nameSegment);
                                if (mapValue) {
                                    //Match, update name to the new value.
                                    foundMap = mapValue;
                                    foundI = i;
                                    break outerLoop;
                                }
                            }
                        }
                    }

                    //Check for a star map match, but just hold on to it,
                    //if there is a shorter segment match later in a matching
                    //config, then favor over this star map.
                    if (!foundStarMap && starMap && getOwn(starMap, nameSegment)) {
                        foundStarMap = getOwn(starMap, nameSegment);
                        starI = i;
                    }
                }

                if (!foundMap && foundStarMap) {
                    foundMap = foundStarMap;
                    foundI = starI;
                }

                if (foundMap) {
                    nameParts.splice(0, foundI, foundMap);
                    name = nameParts.join('/');
                }
            }

            // If the name points to a package's name, use
            // the package main instead.
            pkgMain = getOwn(config.pkgs, name);

            return pkgMain ? pkgMain : name;
        }

        function removeScript(name) {
            if (isBrowser) {
                each(scripts(), function (scriptNode) {
                    if (scriptNode.getAttribute('data-requiremodule') === name &&
                            scriptNode.getAttribute('data-requirecontext') === context.contextName) {
                        scriptNode.parentNode.removeChild(scriptNode);
                        return true;
                    }
                });
            }
        }

        function hasPathFallback(id) {
            var pathConfig = getOwn(config.paths, id);
            if (pathConfig && isArray(pathConfig) && pathConfig.length > 1) {
                //Pop off the first array value, since it failed, and
                //retry
                pathConfig.shift();
                context.require.undef(id);

                //Custom require that does not do map translation, since
                //ID is "absolute", already mapped/resolved.
                context.makeRequire(null, {
                    skipMap: true
                })([id]);

                return true;
            }
        }

        //Turns a plugin!resource to [plugin, resource]
        //with the plugin being undefined if the name
        //did not have a plugin prefix.
        function splitPrefix(name) {
            var prefix,
                index = name ? name.indexOf('!') : -1;
            if (index > -1) {
                prefix = name.substring(0, index);
                name = name.substring(index + 1, name.length);
            }
            return [prefix, name];
        }

        /**
         * Creates a module mapping that includes plugin prefix, module
         * name, and path. If parentModuleMap is provided it will
         * also normalize the name via require.normalize()
         *
         * @param {String} name the module name
         * @param {String} [parentModuleMap] parent module map
         * for the module name, used to resolve relative names.
         * @param {Boolean} isNormalized: is the ID already normalized.
         * This is true if this call is done for a define() module ID.
         * @param {Boolean} applyMap: apply the map config to the ID.
         * Should only be true if this map is for a dependency.
         *
         * @returns {Object}
         */
        function makeModuleMap(name, parentModuleMap, isNormalized, applyMap) {
            var url, pluginModule, suffix, nameParts,
                prefix = null,
                parentName = parentModuleMap ? parentModuleMap.name : null,
                originalName = name,
                isDefine = true,
                normalizedName = '';

            //If no name, then it means it is a require call, generate an
            //internal name.
            if (!name) {
                isDefine = false;
                name = '_@r' + (requireCounter += 1);
            }

            nameParts = splitPrefix(name);
            prefix = nameParts[0];
            name = nameParts[1];

            if (prefix) {
                prefix = normalize(prefix, parentName, applyMap);
                pluginModule = getOwn(defined, prefix);
            }

            //Account for relative paths if there is a base name.
            if (name) {
                if (prefix) {
                    if (pluginModule && pluginModule.normalize) {
                        //Plugin is loaded, use its normalize method.
                        normalizedName = pluginModule.normalize(name, function (name) {
                            return normalize(name, parentName, applyMap);
                        });
                    } else {
                        // If nested plugin references, then do not try to
                        // normalize, as it will not normalize correctly. This
                        // places a restriction on resourceIds, and the longer
                        // term solution is not to normalize until plugins are
                        // loaded and all normalizations to allow for async
                        // loading of a loader plugin. But for now, fixes the
                        // common uses. Details in #1131
                        normalizedName = name.indexOf('!') === -1 ?
                                         normalize(name, parentName, applyMap) :
                                         name;
                    }
                } else {
                    //A regular module.
                    normalizedName = normalize(name, parentName, applyMap);

                    //Normalized name may be a plugin ID due to map config
                    //application in normalize. The map config values must
                    //already be normalized, so do not need to redo that part.
                    nameParts = splitPrefix(normalizedName);
                    prefix = nameParts[0];
                    normalizedName = nameParts[1];
                    isNormalized = true;

                    url = context.nameToUrl(normalizedName);
                }
            }

            //If the id is a plugin id that cannot be determined if it needs
            //normalization, stamp it with a unique ID so two matching relative
            //ids that may conflict can be separate.
            suffix = prefix && !pluginModule && !isNormalized ?
                     '_unnormalized' + (unnormalizedCounter += 1) :
                     '';

            return {
                prefix: prefix,
                name: normalizedName,
                parentMap: parentModuleMap,
                unnormalized: !!suffix,
                url: url,
                originalName: originalName,
                isDefine: isDefine,
                id: (prefix ?
                        prefix + '!' + normalizedName :
                        normalizedName) + suffix
            };
        }

        function getModule(depMap) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (!mod) {
                mod = registry[id] = new context.Module(depMap);
            }

            return mod;
        }

        function on(depMap, name, fn) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (hasProp(defined, id) &&
                    (!mod || mod.defineEmitComplete)) {
                if (name === 'defined') {
                    fn(defined[id]);
                }
            } else {
                mod = getModule(depMap);
                if (mod.error && name === 'error') {
                    fn(mod.error);
                } else {
                    mod.on(name, fn);
                }
            }
        }

        function onError(err, errback) {
            var ids = err.requireModules,
                notified = false;

            if (errback) {
                errback(err);
            } else {
                each(ids, function (id) {
                    var mod = getOwn(registry, id);
                    if (mod) {
                        //Set error on module, so it skips timeout checks.
                        mod.error = err;
                        if (mod.events.error) {
                            notified = true;
                            mod.emit('error', err);
                        }
                    }
                });

                if (!notified) {
                    req.onError(err);
                }
            }
        }

        /**
         * Internal method to transfer globalQueue items to this context's
         * defQueue.
         */
        function takeGlobalQueue() {
            //Push all the globalDefQueue items into the context's defQueue
            if (globalDefQueue.length) {
                each(globalDefQueue, function(queueItem) {
                    var id = queueItem[0];
                    if (typeof id === 'string') {
                        context.defQueueMap[id] = true;
                    }
                    defQueue.push(queueItem);
                });
                globalDefQueue = [];
            }
        }

        handlers = {
            'require': function (mod) {
                if (mod.require) {
                    return mod.require;
                } else {
                    return (mod.require = context.makeRequire(mod.map));
                }
            },
            'exports': function (mod) {
                mod.usingExports = true;
                if (mod.map.isDefine) {
                    if (mod.exports) {
                        return (defined[mod.map.id] = mod.exports);
                    } else {
                        return (mod.exports = defined[mod.map.id] = {});
                    }
                }
            },
            'module': function (mod) {
                if (mod.module) {
                    return mod.module;
                } else {
                    return (mod.module = {
                        id: mod.map.id,
                        uri: mod.map.url,
                        config: function () {
                            return getOwn(config.config, mod.map.id) || {};
                        },
                        exports: mod.exports || (mod.exports = {})
                    });
                }
            }
        };

        function cleanRegistry(id) {
            //Clean up machinery used for waiting modules.
            delete registry[id];
            delete enabledRegistry[id];
        }

        function breakCycle(mod, traced, processed) {
            var id = mod.map.id;

            if (mod.error) {
                mod.emit('error', mod.error);
            } else {
                traced[id] = true;
                each(mod.depMaps, function (depMap, i) {
                    var depId = depMap.id,
                        dep = getOwn(registry, depId);

                    //Only force things that have not completed
                    //being defined, so still in the registry,
                    //and only if it has not been matched up
                    //in the module already.
                    if (dep && !mod.depMatched[i] && !processed[depId]) {
                        if (getOwn(traced, depId)) {
                            mod.defineDep(i, defined[depId]);
                            mod.check(); //pass false?
                        } else {
                            breakCycle(dep, traced, processed);
                        }
                    }
                });
                processed[id] = true;
            }
        }

        function checkLoaded() {
            var err, usingPathFallback,
                waitInterval = config.waitSeconds * 1000,
                //It is possible to disable the wait interval by using waitSeconds of 0.
                expired = waitInterval && (context.startTime + waitInterval) < new Date().getTime(),
                noLoads = [],
                reqCalls = [],
                stillLoading = false,
                needCycleCheck = true;

            //Do not bother if this call was a result of a cycle break.
            if (inCheckLoaded) {
                return;
            }

            inCheckLoaded = true;

            //Figure out the state of all the modules.
            eachProp(enabledRegistry, function (mod) {
                var map = mod.map,
                    modId = map.id;

                //Skip things that are not enabled or in error state.
                if (!mod.enabled) {
                    return;
                }

                if (!map.isDefine) {
                    reqCalls.push(mod);
                }

                if (!mod.error) {
                    //If the module should be executed, and it has not
                    //been inited and time is up, remember it.
                    if (!mod.inited && expired) {
                        if (hasPathFallback(modId)) {
                            usingPathFallback = true;
                            stillLoading = true;
                        } else {
                            noLoads.push(modId);
                            removeScript(modId);
                        }
                    } else if (!mod.inited && mod.fetched && map.isDefine) {
                        stillLoading = true;
                        if (!map.prefix) {
                            //No reason to keep looking for unfinished
                            //loading. If the only stillLoading is a
                            //plugin resource though, keep going,
                            //because it may be that a plugin resource
                            //is waiting on a non-plugin cycle.
                            return (needCycleCheck = false);
                        }
                    }
                }
            });

            if (expired && noLoads.length) {
                //If wait time expired, throw error of unloaded modules.
                err = makeError('timeout', 'Load timeout for modules: ' + noLoads, null, noLoads);
                err.contextName = context.contextName;
                return onError(err);
            }

            //Not expired, check for a cycle.
            if (needCycleCheck) {
                each(reqCalls, function (mod) {
                    breakCycle(mod, {}, {});
                });
            }

            //If still waiting on loads, and the waiting load is something
            //other than a plugin resource, or there are still outstanding
            //scripts, then just try back later.
            if ((!expired || usingPathFallback) && stillLoading) {
                //Something is still waiting to load. Wait for it, but only
                //if a timeout is not already in effect.
                if ((isBrowser || isWebWorker) && !checkLoadedTimeoutId) {
                    checkLoadedTimeoutId = setTimeout(function () {
                        checkLoadedTimeoutId = 0;
                        checkLoaded();
                    }, 50);
                }
            }

            inCheckLoaded = false;
        }

        Module = function (map) {
            this.events = getOwn(undefEvents, map.id) || {};
            this.map = map;
            this.shim = getOwn(config.shim, map.id);
            this.depExports = [];
            this.depMaps = [];
            this.depMatched = [];
            this.pluginMaps = {};
            this.depCount = 0;

            /* this.exports this.factory
               this.depMaps = [],
               this.enabled, this.fetched
            */
        };

        Module.prototype = {
            init: function (depMaps, factory, errback, options) {
                options = options || {};

                //Do not do more inits if already done. Can happen if there
                //are multiple define calls for the same module. That is not
                //a normal, common case, but it is also not unexpected.
                if (this.inited) {
                    return;
                }

                this.factory = factory;

                if (errback) {
                    //Register for errors on this module.
                    this.on('error', errback);
                } else if (this.events.error) {
                    //If no errback already, but there are error listeners
                    //on this module, set up an errback to pass to the deps.
                    errback = bind(this, function (err) {
                        this.emit('error', err);
                    });
                }

                //Do a copy of the dependency array, so that
                //source inputs are not modified. For example
                //"shim" deps are passed in here directly, and
                //doing a direct modification of the depMaps array
                //would affect that config.
                this.depMaps = depMaps && depMaps.slice(0);

                this.errback = errback;

                //Indicate this module has be initialized
                this.inited = true;

                this.ignore = options.ignore;

                //Could have option to init this module in enabled mode,
                //or could have been previously marked as enabled. However,
                //the dependencies are not known until init is called. So
                //if enabled previously, now trigger dependencies as enabled.
                if (options.enabled || this.enabled) {
                    //Enable this module and dependencies.
                    //Will call this.check()
                    this.enable();
                } else {
                    this.check();
                }
            },

            defineDep: function (i, depExports) {
                //Because of cycles, defined callback for a given
                //export can be called more than once.
                if (!this.depMatched[i]) {
                    this.depMatched[i] = true;
                    this.depCount -= 1;
                    this.depExports[i] = depExports;
                }
            },

            fetch: function () {
                if (this.fetched) {
                    return;
                }
                this.fetched = true;

                context.startTime = (new Date()).getTime();

                var map = this.map;

                //If the manager is for a plugin managed resource,
                //ask the plugin to load it now.
                if (this.shim) {
                    context.makeRequire(this.map, {
                        enableBuildCallback: true
                    })(this.shim.deps || [], bind(this, function () {
                        return map.prefix ? this.callPlugin() : this.load();
                    }));
                } else {
                    //Regular dependency.
                    return map.prefix ? this.callPlugin() : this.load();
                }
            },

            load: function () {
                var url = this.map.url;

                //Regular dependency.
                if (!urlFetched[url]) {
                    urlFetched[url] = true;
                    context.load(this.map.id, url);
                }
            },

            /**
             * Checks if the module is ready to define itself, and if so,
             * define it.
             */
            check: function () {
                if (!this.enabled || this.enabling) {
                    return;
                }

                var err, cjsModule,
                    id = this.map.id,
                    depExports = this.depExports,
                    exports = this.exports,
                    factory = this.factory;

                if (!this.inited) {
                    // Only fetch if not already in the defQueue.
                    if (!hasProp(context.defQueueMap, id)) {
                        this.fetch();
                    }
                } else if (this.error) {
                    this.emit('error', this.error);
                } else if (!this.defining) {
                    //The factory could trigger another require call
                    //that would result in checking this module to
                    //define itself again. If already in the process
                    //of doing that, skip this work.
                    this.defining = true;

                    if (this.depCount < 1 && !this.defined) {
                        if (isFunction(factory)) {
                            //If there is an error listener, favor passing
                            //to that instead of throwing an error. However,
                            //only do it for define()'d  modules. require
                            //errbacks should not be called for failures in
                            //their callbacks (#699). However if a global
                            //onError is set, use that.
                            if ((this.events.error && this.map.isDefine) ||
                                req.onError !== defaultOnError) {
                                try {
                                    exports = context.execCb(id, factory, depExports, exports);
                                } catch (e) {
                                    err = e;
                                }
                            } else {
                                exports = context.execCb(id, factory, depExports, exports);
                            }

                            // Favor return value over exports. If node/cjs in play,
                            // then will not have a return value anyway. Favor
                            // module.exports assignment over exports object.
                            if (this.map.isDefine && exports === undefined) {
                                cjsModule = this.module;
                                if (cjsModule) {
                                    exports = cjsModule.exports;
                                } else if (this.usingExports) {
                                    //exports already set the defined value.
                                    exports = this.exports;
                                }
                            }

                            if (err) {
                                err.requireMap = this.map;
                                err.requireModules = this.map.isDefine ? [this.map.id] : null;
                                err.requireType = this.map.isDefine ? 'define' : 'require';
                                return onError((this.error = err));
                            }

                        } else {
                            //Just a literal value
                            exports = factory;
                        }

                        this.exports = exports;

                        if (this.map.isDefine && !this.ignore) {
                            defined[id] = exports;

                            if (req.onResourceLoad) {
                                var resLoadMaps = [];
                                each(this.depMaps, function (depMap) {
                                    resLoadMaps.push(depMap.normalizedMap || depMap);
                                });
                                req.onResourceLoad(context, this.map, resLoadMaps);
                            }
                        }

                        //Clean up
                        cleanRegistry(id);

                        this.defined = true;
                    }

                    //Finished the define stage. Allow calling check again
                    //to allow define notifications below in the case of a
                    //cycle.
                    this.defining = false;

                    if (this.defined && !this.defineEmitted) {
                        this.defineEmitted = true;
                        this.emit('defined', this.exports);
                        this.defineEmitComplete = true;
                    }

                }
            },

            callPlugin: function () {
                var map = this.map,
                    id = map.id,
                    //Map already normalized the prefix.
                    pluginMap = makeModuleMap(map.prefix);

                //Mark this as a dependency for this plugin, so it
                //can be traced for cycles.
                this.depMaps.push(pluginMap);

                on(pluginMap, 'defined', bind(this, function (plugin) {
                    var load, normalizedMap, normalizedMod,
                        bundleId = getOwn(bundlesMap, this.map.id),
                        name = this.map.name,
                        parentName = this.map.parentMap ? this.map.parentMap.name : null,
                        localRequire = context.makeRequire(map.parentMap, {
                            enableBuildCallback: true
                        });

                    //If current map is not normalized, wait for that
                    //normalized name to load instead of continuing.
                    if (this.map.unnormalized) {
                        //Normalize the ID if the plugin allows it.
                        if (plugin.normalize) {
                            name = plugin.normalize(name, function (name) {
                                return normalize(name, parentName, true);
                            }) || '';
                        }

                        //prefix and name should already be normalized, no need
                        //for applying map config again either.
                        normalizedMap = makeModuleMap(map.prefix + '!' + name,
                                                      this.map.parentMap);
                        on(normalizedMap,
                            'defined', bind(this, function (value) {
                                this.map.normalizedMap = normalizedMap;
                                this.init([], function () { return value; }, null, {
                                    enabled: true,
                                    ignore: true
                                });
                            }));

                        normalizedMod = getOwn(registry, normalizedMap.id);
                        if (normalizedMod) {
                            //Mark this as a dependency for this plugin, so it
                            //can be traced for cycles.
                            this.depMaps.push(normalizedMap);

                            if (this.events.error) {
                                normalizedMod.on('error', bind(this, function (err) {
                                    this.emit('error', err);
                                }));
                            }
                            normalizedMod.enable();
                        }

                        return;
                    }

                    //If a paths config, then just load that file instead to
                    //resolve the plugin, as it is built into that paths layer.
                    if (bundleId) {
                        this.map.url = context.nameToUrl(bundleId);
                        this.load();
                        return;
                    }

                    load = bind(this, function (value) {
                        this.init([], function () { return value; }, null, {
                            enabled: true
                        });
                    });

                    load.error = bind(this, function (err) {
                        this.inited = true;
                        this.error = err;
                        err.requireModules = [id];

                        //Remove temp unnormalized modules for this module,
                        //since they will never be resolved otherwise now.
                        eachProp(registry, function (mod) {
                            if (mod.map.id.indexOf(id + '_unnormalized') === 0) {
                                cleanRegistry(mod.map.id);
                            }
                        });

                        onError(err);
                    });

                    //Allow plugins to load other code without having to know the
                    //context or how to 'complete' the load.
                    load.fromText = bind(this, function (text, textAlt) {
                        /*jslint evil: true */
                        var moduleName = map.name,
                            moduleMap = makeModuleMap(moduleName),
                            hasInteractive = useInteractive;

                        //As of 2.1.0, support just passing the text, to reinforce
                        //fromText only being called once per resource. Still
                        //support old style of passing moduleName but discard
                        //that moduleName in favor of the internal ref.
                        if (textAlt) {
                            text = textAlt;
                        }

                        //Turn off interactive script matching for IE for any define
                        //calls in the text, then turn it back on at the end.
                        if (hasInteractive) {
                            useInteractive = false;
                        }

                        //Prime the system by creating a module instance for
                        //it.
                        getModule(moduleMap);

                        //Transfer any config to this other module.
                        if (hasProp(config.config, id)) {
                            config.config[moduleName] = config.config[id];
                        }

                        try {
                            req.exec(text);
                        } catch (e) {
                            return onError(makeError('fromtexteval',
                                             'fromText eval for ' + id +
                                            ' failed: ' + e,
                                             e,
                                             [id]));
                        }

                        if (hasInteractive) {
                            useInteractive = true;
                        }

                        //Mark this as a dependency for the plugin
                        //resource
                        this.depMaps.push(moduleMap);

                        //Support anonymous modules.
                        context.completeLoad(moduleName);

                        //Bind the value of that module to the value for this
                        //resource ID.
                        localRequire([moduleName], load);
                    });

                    //Use parentName here since the plugin's name is not reliable,
                    //could be some weird string with no path that actually wants to
                    //reference the parentName's path.
                    plugin.load(map.name, localRequire, load, config);
                }));

                context.enable(pluginMap, this);
                this.pluginMaps[pluginMap.id] = pluginMap;
            },

            enable: function () {
                enabledRegistry[this.map.id] = this;
                this.enabled = true;

                //Set flag mentioning that the module is enabling,
                //so that immediate calls to the defined callbacks
                //for dependencies do not trigger inadvertent load
                //with the depCount still being zero.
                this.enabling = true;

                //Enable each dependency
                each(this.depMaps, bind(this, function (depMap, i) {
                    var id, mod, handler;

                    if (typeof depMap === 'string') {
                        //Dependency needs to be converted to a depMap
                        //and wired up to this module.
                        depMap = makeModuleMap(depMap,
                                               (this.map.isDefine ? this.map : this.map.parentMap),
                                               false,
                                               !this.skipMap);
                        this.depMaps[i] = depMap;

                        handler = getOwn(handlers, depMap.id);

                        if (handler) {
                            this.depExports[i] = handler(this);
                            return;
                        }

                        this.depCount += 1;

                        on(depMap, 'defined', bind(this, function (depExports) {
                            if (this.undefed) {
                                return;
                            }
                            this.defineDep(i, depExports);
                            this.check();
                        }));

                        if (this.errback) {
                            on(depMap, 'error', bind(this, this.errback));
                        } else if (this.events.error) {
                            // No direct errback on this module, but something
                            // else is listening for errors, so be sure to
                            // propagate the error correctly.
                            on(depMap, 'error', bind(this, function(err) {
                                this.emit('error', err);
                            }));
                        }
                    }

                    id = depMap.id;
                    mod = registry[id];

                    //Skip special modules like 'require', 'exports', 'module'
                    //Also, don't call enable if it is already enabled,
                    //important in circular dependency cases.
                    if (!hasProp(handlers, id) && mod && !mod.enabled) {
                        context.enable(depMap, this);
                    }
                }));

                //Enable each plugin that is used in
                //a dependency
                eachProp(this.pluginMaps, bind(this, function (pluginMap) {
                    var mod = getOwn(registry, pluginMap.id);
                    if (mod && !mod.enabled) {
                        context.enable(pluginMap, this);
                    }
                }));

                this.enabling = false;

                this.check();
            },

            on: function (name, cb) {
                var cbs = this.events[name];
                if (!cbs) {
                    cbs = this.events[name] = [];
                }
                cbs.push(cb);
            },

            emit: function (name, evt) {
                each(this.events[name], function (cb) {
                    cb(evt);
                });
                if (name === 'error') {
                    //Now that the error handler was triggered, remove
                    //the listeners, since this broken Module instance
                    //can stay around for a while in the registry.
                    delete this.events[name];
                }
            }
        };

        function callGetModule(args) {
            //Skip modules already defined.
            if (!hasProp(defined, args[0])) {
                getModule(makeModuleMap(args[0], null, true)).init(args[1], args[2]);
            }
        }

        function removeListener(node, func, name, ieName) {
            //Favor detachEvent because of IE9
            //issue, see attachEvent/addEventListener comment elsewhere
            //in this file.
            if (node.detachEvent && !isOpera) {
                //Probably IE. If not it will throw an error, which will be
                //useful to know.
                if (ieName) {
                    node.detachEvent(ieName, func);
                }
            } else {
                node.removeEventListener(name, func, false);
            }
        }

        /**
         * Given an event from a script node, get the requirejs info from it,
         * and then removes the event listeners on the node.
         * @param {Event} evt
         * @returns {Object}
         */
        function getScriptData(evt) {
            //Using currentTarget instead of target for Firefox 2.0's sake. Not
            //all old browsers will be supported, but this one was easy enough
            //to support and still makes sense.
            var node = evt.currentTarget || evt.srcElement;

            //Remove the listeners once here.
            removeListener(node, context.onScriptLoad, 'load', 'onreadystatechange');
            removeListener(node, context.onScriptError, 'error');

            return {
                node: node,
                id: node && node.getAttribute('data-requiremodule')
            };
        }

        function intakeDefines() {
            var args;

            //Any defined modules in the global queue, intake them now.
            takeGlobalQueue();

            //Make sure any remaining defQueue items get properly processed.
            while (defQueue.length) {
                args = defQueue.shift();
                if (args[0] === null) {
                    return onError(makeError('mismatch', 'Mismatched anonymous define() module: ' +
                        args[args.length - 1]));
                } else {
                    //args are id, deps, factory. Should be normalized by the
                    //define() function.
                    callGetModule(args);
                }
            }
            context.defQueueMap = {};
        }

        context = {
            config: config,
            contextName: contextName,
            registry: registry,
            defined: defined,
            urlFetched: urlFetched,
            defQueue: defQueue,
            defQueueMap: {},
            Module: Module,
            makeModuleMap: makeModuleMap,
            nextTick: req.nextTick,
            onError: onError,

            /**
             * Set a configuration for the context.
             * @param {Object} cfg config object to integrate.
             */
            configure: function (cfg) {
                //Make sure the baseUrl ends in a slash.
                if (cfg.baseUrl) {
                    if (cfg.baseUrl.charAt(cfg.baseUrl.length - 1) !== '/') {
                        cfg.baseUrl += '/';
                    }
                }

                // Convert old style urlArgs string to a function.
                if (typeof cfg.urlArgs === 'string') {
                    var urlArgs = cfg.urlArgs;
                    cfg.urlArgs = function(id, url) {
                        return (url.indexOf('?') === -1 ? '?' : '&') + urlArgs;
                    };
                }

                //Save off the paths since they require special processing,
                //they are additive.
                var shim = config.shim,
                    objs = {
                        paths: true,
                        bundles: true,
                        config: true,
                        map: true
                    };

                eachProp(cfg, function (value, prop) {
                    if (objs[prop]) {
                        if (!config[prop]) {
                            config[prop] = {};
                        }
                        mixin(config[prop], value, true, true);
                    } else {
                        config[prop] = value;
                    }
                });

                //Reverse map the bundles
                if (cfg.bundles) {
                    eachProp(cfg.bundles, function (value, prop) {
                        each(value, function (v) {
                            if (v !== prop) {
                                bundlesMap[v] = prop;
                            }
                        });
                    });
                }

                //Merge shim
                if (cfg.shim) {
                    eachProp(cfg.shim, function (value, id) {
                        //Normalize the structure
                        if (isArray(value)) {
                            value = {
                                deps: value
                            };
                        }
                        if ((value.exports || value.init) && !value.exportsFn) {
                            value.exportsFn = context.makeShimExports(value);
                        }
                        shim[id] = value;
                    });
                    config.shim = shim;
                }

                //Adjust packages if necessary.
                if (cfg.packages) {
                    each(cfg.packages, function (pkgObj) {
                        var location, name;

                        pkgObj = typeof pkgObj === 'string' ? {name: pkgObj} : pkgObj;

                        name = pkgObj.name;
                        location = pkgObj.location;
                        if (location) {
                            config.paths[name] = pkgObj.location;
                        }

                        //Save pointer to main module ID for pkg name.
                        //Remove leading dot in main, so main paths are normalized,
                        //and remove any trailing .js, since different package
                        //envs have different conventions: some use a module name,
                        //some use a file name.
                        config.pkgs[name] = pkgObj.name + '/' + (pkgObj.main || 'main')
                                     .replace(currDirRegExp, '')
                                     .replace(jsSuffixRegExp, '');
                    });
                }

                //If there are any "waiting to execute" modules in the registry,
                //update the maps for them, since their info, like URLs to load,
                //may have changed.
                eachProp(registry, function (mod, id) {
                    //If module already has init called, since it is too
                    //late to modify them, and ignore unnormalized ones
                    //since they are transient.
                    if (!mod.inited && !mod.map.unnormalized) {
                        mod.map = makeModuleMap(id, null, true);
                    }
                });

                //If a deps array or a config callback is specified, then call
                //require with those args. This is useful when require is defined as a
                //config object before require.js is loaded.
                if (cfg.deps || cfg.callback) {
                    context.require(cfg.deps || [], cfg.callback);
                }
            },

            makeShimExports: function (value) {
                function fn() {
                    var ret;
                    if (value.init) {
                        ret = value.init.apply(global, arguments);
                    }
                    return ret || (value.exports && getGlobal(value.exports));
                }
                return fn;
            },

            makeRequire: function (relMap, options) {
                options = options || {};

                function localRequire(deps, callback, errback) {
                    var id, map, requireMod;

                    if (options.enableBuildCallback && callback && isFunction(callback)) {
                        callback.__requireJsBuild = true;
                    }

                    if (typeof deps === 'string') {
                        if (isFunction(callback)) {
                            //Invalid call
                            return onError(makeError('requireargs', 'Invalid require call'), errback);
                        }

                        //If require|exports|module are requested, get the
                        //value for them from the special handlers. Caveat:
                        //this only works while module is being defined.
                        if (relMap && hasProp(handlers, deps)) {
                            return handlers[deps](registry[relMap.id]);
                        }

                        //Synchronous access to one module. If require.get is
                        //available (as in the Node adapter), prefer that.
                        if (req.get) {
                            return req.get(context, deps, relMap, localRequire);
                        }

                        //Normalize module name, if it contains . or ..
                        map = makeModuleMap(deps, relMap, false, true);
                        id = map.id;

                        if (!hasProp(defined, id)) {
                            return onError(makeError('notloaded', 'Module name "' +
                                        id +
                                        '" has not been loaded yet for context: ' +
                                        contextName +
                                        (relMap ? '' : '. Use require([])')));
                        }
                        return defined[id];
                    }

                    //Grab defines waiting in the global queue.
                    intakeDefines();

                    //Mark all the dependencies as needing to be loaded.
                    context.nextTick(function () {
                        //Some defines could have been added since the
                        //require call, collect them.
                        intakeDefines();

                        requireMod = getModule(makeModuleMap(null, relMap));

                        //Store if map config should be applied to this require
                        //call for dependencies.
                        requireMod.skipMap = options.skipMap;

                        requireMod.init(deps, callback, errback, {
                            enabled: true
                        });

                        checkLoaded();
                    });

                    return localRequire;
                }

                mixin(localRequire, {
                    isBrowser: isBrowser,

                    /**
                     * Converts a module name + .extension into an URL path.
                     * *Requires* the use of a module name. It does not support using
                     * plain URLs like nameToUrl.
                     */
                    toUrl: function (moduleNamePlusExt) {
                        var ext,
                            index = moduleNamePlusExt.lastIndexOf('.'),
                            segment = moduleNamePlusExt.split('/')[0],
                            isRelative = segment === '.' || segment === '..';

                        //Have a file extension alias, and it is not the
                        //dots from a relative path.
                        if (index !== -1 && (!isRelative || index > 1)) {
                            ext = moduleNamePlusExt.substring(index, moduleNamePlusExt.length);
                            moduleNamePlusExt = moduleNamePlusExt.substring(0, index);
                        }

                        return context.nameToUrl(normalize(moduleNamePlusExt,
                                                relMap && relMap.id, true), ext,  true);
                    },

                    defined: function (id) {
                        return hasProp(defined, makeModuleMap(id, relMap, false, true).id);
                    },

                    specified: function (id) {
                        id = makeModuleMap(id, relMap, false, true).id;
                        return hasProp(defined, id) || hasProp(registry, id);
                    }
                });

                //Only allow undef on top level require calls
                if (!relMap) {
                    localRequire.undef = function (id) {
                        //Bind any waiting define() calls to this context,
                        //fix for #408
                        takeGlobalQueue();

                        var map = makeModuleMap(id, relMap, true),
                            mod = getOwn(registry, id);

                        mod.undefed = true;
                        removeScript(id);

                        delete defined[id];
                        delete urlFetched[map.url];
                        delete undefEvents[id];

                        //Clean queued defines too. Go backwards
                        //in array so that the splices do not
                        //mess up the iteration.
                        eachReverse(defQueue, function(args, i) {
                            if (args[0] === id) {
                                defQueue.splice(i, 1);
                            }
                        });
                        delete context.defQueueMap[id];

                        if (mod) {
                            //Hold on to listeners in case the
                            //module will be attempted to be reloaded
                            //using a different config.
                            if (mod.events.defined) {
                                undefEvents[id] = mod.events;
                            }

                            cleanRegistry(id);
                        }
                    };
                }

                return localRequire;
            },

            /**
             * Called to enable a module if it is still in the registry
             * awaiting enablement. A second arg, parent, the parent module,
             * is passed in for context, when this method is overridden by
             * the optimizer. Not shown here to keep code compact.
             */
            enable: function (depMap) {
                var mod = getOwn(registry, depMap.id);
                if (mod) {
                    getModule(depMap).enable();
                }
            },

            /**
             * Internal method used by environment adapters to complete a load event.
             * A load event could be a script load or just a load pass from a synchronous
             * load call.
             * @param {String} moduleName the name of the module to potentially complete.
             */
            completeLoad: function (moduleName) {
                var found, args, mod,
                    shim = getOwn(config.shim, moduleName) || {},
                    shExports = shim.exports;

                takeGlobalQueue();

                while (defQueue.length) {
                    args = defQueue.shift();
                    if (args[0] === null) {
                        args[0] = moduleName;
                        //If already found an anonymous module and bound it
                        //to this name, then this is some other anon module
                        //waiting for its completeLoad to fire.
                        if (found) {
                            break;
                        }
                        found = true;
                    } else if (args[0] === moduleName) {
                        //Found matching define call for this script!
                        found = true;
                    }

                    callGetModule(args);
                }
                context.defQueueMap = {};

                //Do this after the cycle of callGetModule in case the result
                //of those calls/init calls changes the registry.
                mod = getOwn(registry, moduleName);

                if (!found && !hasProp(defined, moduleName) && mod && !mod.inited) {
                    if (config.enforceDefine && (!shExports || !getGlobal(shExports))) {
                        if (hasPathFallback(moduleName)) {
                            return;
                        } else {
                            return onError(makeError('nodefine',
                                             'No define call for ' + moduleName,
                                             null,
                                             [moduleName]));
                        }
                    } else {
                        //A script that does not call define(), so just simulate
                        //the call for it.
                        callGetModule([moduleName, (shim.deps || []), shim.exportsFn]);
                    }
                }

                checkLoaded();
            },

            /**
             * Converts a module name to a file path. Supports cases where
             * moduleName may actually be just an URL.
             * Note that it **does not** call normalize on the moduleName,
             * it is assumed to have already been normalized. This is an
             * internal API, not a public one. Use toUrl for the public API.
             */
            nameToUrl: function (moduleName, ext, skipExt) {
                var paths, syms, i, parentModule, url,
                    parentPath, bundleId,
                    pkgMain = getOwn(config.pkgs, moduleName);

                if (pkgMain) {
                    moduleName = pkgMain;
                }

                bundleId = getOwn(bundlesMap, moduleName);

                if (bundleId) {
                    return context.nameToUrl(bundleId, ext, skipExt);
                }

                //If a colon is in the URL, it indicates a protocol is used and it is just
                //an URL to a file, or if it starts with a slash, contains a query arg (i.e. ?)
                //or ends with .js, then assume the user meant to use an url and not a module id.
                //The slash is important for protocol-less URLs as well as full paths.
                if (req.jsExtRegExp.test(moduleName)) {
                    //Just a plain path, not module name lookup, so just return it.
                    //Add extension if it is included. This is a bit wonky, only non-.js things pass
                    //an extension, this method probably needs to be reworked.
                    url = moduleName + (ext || '');
                } else {
                    //A module that needs to be converted to a path.
                    paths = config.paths;

                    syms = moduleName.split('/');
                    //For each module name segment, see if there is a path
                    //registered for it. Start with most specific name
                    //and work up from it.
                    for (i = syms.length; i > 0; i -= 1) {
                        parentModule = syms.slice(0, i).join('/');

                        parentPath = getOwn(paths, parentModule);
                        if (parentPath) {
                            //If an array, it means there are a few choices,
                            //Choose the one that is desired
                            if (isArray(parentPath)) {
                                parentPath = parentPath[0];
                            }
                            syms.splice(0, i, parentPath);
                            break;
                        }
                    }

                    //Join the path parts together, then figure out if baseUrl is needed.
                    url = syms.join('/');
                    url += (ext || (/^data\:|^blob\:|\?/.test(url) || skipExt ? '' : '.js'));
                    url = (url.charAt(0) === '/' || url.match(/^[\w\+\.\-]+:/) ? '' : config.baseUrl) + url;
                }

                return config.urlArgs && !/^blob\:/.test(url) ?
                       url + config.urlArgs(moduleName, url) : url;
            },

            //Delegates to req.load. Broken out as a separate function to
            //allow overriding in the optimizer.
            load: function (id, url) {
                req.load(context, id, url);
            },

            /**
             * Executes a module callback function. Broken out as a separate function
             * solely to allow the build system to sequence the files in the built
             * layer in the right sequence.
             *
             * @private
             */
            execCb: function (name, callback, args, exports) {
                return callback.apply(exports, args);
            },

            /**
             * callback for script loads, used to check status of loading.
             *
             * @param {Event} evt the event from the browser for the script
             * that was loaded.
             */
            onScriptLoad: function (evt) {
                //Using currentTarget instead of target for Firefox 2.0's sake. Not
                //all old browsers will be supported, but this one was easy enough
                //to support and still makes sense.
                if (evt.type === 'load' ||
                        (readyRegExp.test((evt.currentTarget || evt.srcElement).readyState))) {
                    //Reset interactive script so a script node is not held onto for
                    //to long.
                    interactiveScript = null;

                    //Pull out the name of the module and the context.
                    var data = getScriptData(evt);
                    context.completeLoad(data.id);
                }
            },

            /**
             * Callback for script errors.
             */
            onScriptError: function (evt) {
                var data = getScriptData(evt);
                if (!hasPathFallback(data.id)) {
                    var parents = [];
                    eachProp(registry, function(value, key) {
                        if (key.indexOf('_@r') !== 0) {
                            each(value.depMaps, function(depMap) {
                                if (depMap.id === data.id) {
                                    parents.push(key);
                                    return true;
                                }
                            });
                        }
                    });
                    return onError(makeError('scripterror', 'Script error for "' + data.id +
                                             (parents.length ?
                                             '", needed by: ' + parents.join(', ') :
                                             '"'), evt, [data.id]));
                }
            }
        };

        context.require = context.makeRequire();
        return context;
    }

    /**
     * Main entry point.
     *
     * If the only argument to require is a string, then the module that
     * is represented by that string is fetched for the appropriate context.
     *
     * If the first argument is an array, then it will be treated as an array
     * of dependency string names to fetch. An optional function callback can
     * be specified to execute when all of those dependencies are available.
     *
     * Make a local req variable to help Caja compliance (it assumes things
     * on a require that are not standardized), and to give a short
     * name for minification/local scope use.
     */
    req = requirejs = function (deps, callback, errback, optional) {

        //Find the right context, use default
        var context, config,
            contextName = defContextName;

        // Determine if have config object in the call.
        if (!isArray(deps) && typeof deps !== 'string') {
            // deps is a config object
            config = deps;
            if (isArray(callback)) {
                // Adjust args if there are dependencies
                deps = callback;
                callback = errback;
                errback = optional;
            } else {
                deps = [];
            }
        }

        if (config && config.context) {
            contextName = config.context;
        }

        context = getOwn(contexts, contextName);
        if (!context) {
            context = contexts[contextName] = req.s.newContext(contextName);
        }

        if (config) {
            context.configure(config);
        }

        return context.require(deps, callback, errback);
    };

    /**
     * Support require.config() to make it easier to cooperate with other
     * AMD loaders on globally agreed names.
     */
    req.config = function (config) {
        return req(config);
    };

    /**
     * Execute something after the current tick
     * of the event loop. Override for other envs
     * that have a better solution than setTimeout.
     * @param  {Function} fn function to execute later.
     */
    req.nextTick = typeof setTimeout !== 'undefined' ? function (fn) {
        setTimeout(fn, 4);
    } : function (fn) { fn(); };

    /**
     * Export require as a global, but only if it does not already exist.
     */
    if (!require) {
        require = req;
    }

    req.version = version;

    //Used to filter out dependencies that are already paths.
    req.jsExtRegExp = /^\/|:|\?|\.js$/;
    req.isBrowser = isBrowser;
    s = req.s = {
        contexts: contexts,
        newContext: newContext
    };

    //Create default context.
    req({});

    //Exports some context-sensitive methods on global require.
    each([
        'toUrl',
        'undef',
        'defined',
        'specified'
    ], function (prop) {
        //Reference from contexts instead of early binding to default context,
        //so that during builds, the latest instance of the default context
        //with its config gets used.
        req[prop] = function () {
            var ctx = contexts[defContextName];
            return ctx.require[prop].apply(ctx, arguments);
        };
    });

    if (isBrowser) {
        head = s.head = document.getElementsByTagName('head')[0];
        //If BASE tag is in play, using appendChild is a problem for IE6.
        //When that browser dies, this can be removed. Details in this jQuery bug:
        //http://dev.jquery.com/ticket/2709
        baseElement = document.getElementsByTagName('base')[0];
        if (baseElement) {
            head = s.head = baseElement.parentNode;
        }
    }

    /**
     * Any errors that require explicitly generates will be passed to this
     * function. Intercept/override it if you want custom error handling.
     * @param {Error} err the error object.
     */
    req.onError = defaultOnError;

    /**
     * Creates the node for the load command. Only used in browser envs.
     */
    req.createNode = function (config, moduleName, url) {
        var node = config.xhtml ?
                document.createElementNS('http://www.w3.org/1999/xhtml', 'html:script') :
                document.createElement('script');
        node.type = config.scriptType || 'text/javascript';
        node.charset = 'utf-8';
        node.async = true;
        return node;
    };

    /**
     * Does the request to load a module for the browser case.
     * Make this a separate function to allow other environments
     * to override it.
     *
     * @param {Object} context the require context to find state.
     * @param {String} moduleName the name of the module.
     * @param {Object} url the URL to the module.
     */
    req.load = function (context, moduleName, url) {
        var config = (context && context.config) || {},
            node;
        if (isBrowser) {
            //In the browser so use a script tag
            node = req.createNode(config, moduleName, url);

            node.setAttribute('data-requirecontext', context.contextName);
            node.setAttribute('data-requiremodule', moduleName);

            //Set up load listener. Test attachEvent first because IE9 has
            //a subtle issue in its addEventListener and script onload firings
            //that do not match the behavior of all other browsers with
            //addEventListener support, which fire the onload event for a
            //script right after the script execution. See:
            //https://connect.microsoft.com/IE/feedback/details/648057/script-onload-event-is-not-fired-immediately-after-script-execution
            //UNFORTUNATELY Opera implements attachEvent but does not follow the script
            //script execution mode.
            if (node.attachEvent &&
                    //Check if node.attachEvent is artificially added by custom script or
                    //natively supported by browser
                    //read https://github.com/requirejs/requirejs/issues/187
                    //if we can NOT find [native code] then it must NOT natively supported.
                    //in IE8, node.attachEvent does not have toString()
                    //Note the test for "[native code" with no closing brace, see:
                    //https://github.com/requirejs/requirejs/issues/273
                    !(node.attachEvent.toString && node.attachEvent.toString().indexOf('[native code') < 0) &&
                    !isOpera) {
                //Probably IE. IE (at least 6-8) do not fire
                //script onload right after executing the script, so
                //we cannot tie the anonymous define call to a name.
                //However, IE reports the script as being in 'interactive'
                //readyState at the time of the define call.
                useInteractive = true;

                node.attachEvent('onreadystatechange', context.onScriptLoad);
                //It would be great to add an error handler here to catch
                //404s in IE9+. However, onreadystatechange will fire before
                //the error handler, so that does not help. If addEventListener
                //is used, then IE will fire error before load, but we cannot
                //use that pathway given the connect.microsoft.com issue
                //mentioned above about not doing the 'script execute,
                //then fire the script load event listener before execute
                //next script' that other browsers do.
                //Best hope: IE10 fixes the issues,
                //and then destroys all installs of IE 6-9.
                //node.attachEvent('onerror', context.onScriptError);
            } else {
                node.addEventListener('load', context.onScriptLoad, false);
                node.addEventListener('error', context.onScriptError, false);
            }
            node.src = url;

            //Calling onNodeCreated after all properties on the node have been
            //set, but before it is placed in the DOM.
            if (config.onNodeCreated) {
                config.onNodeCreated(node, config, moduleName, url);
            }

            //For some cache cases in IE 6-8, the script executes before the end
            //of the appendChild execution, so to tie an anonymous define
            //call to the module name (which is stored on the node), hold on
            //to a reference to this node, but clear after the DOM insertion.
            currentlyAddingScript = node;
            if (baseElement) {
                head.insertBefore(node, baseElement);
            } else {
                head.appendChild(node);
            }
            currentlyAddingScript = null;

            return node;
        } else if (isWebWorker) {
            try {
                //In a web worker, use importScripts. This is not a very
                //efficient use of importScripts, importScripts will block until
                //its script is downloaded and evaluated. However, if web workers
                //are in play, the expectation is that a build has been done so
                //that only one script needs to be loaded anyway. This may need
                //to be reevaluated if other use cases become common.

                // Post a task to the event loop to work around a bug in WebKit
                // where the worker gets garbage-collected after calling
                // importScripts(): https://webkit.org/b/153317
                setTimeout(function() {}, 0);
                importScripts(url);

                //Account for anonymous modules
                context.completeLoad(moduleName);
            } catch (e) {
                context.onError(makeError('importscripts',
                                'importScripts failed for ' +
                                    moduleName + ' at ' + url,
                                e,
                                [moduleName]));
            }
        }
    };

    function getInteractiveScript() {
        if (interactiveScript && interactiveScript.readyState === 'interactive') {
            return interactiveScript;
        }

        eachReverse(scripts(), function (script) {
            if (script.readyState === 'interactive') {
                return (interactiveScript = script);
            }
        });
        return interactiveScript;
    }

    //Look for a data-main script attribute, which could also adjust the baseUrl.
    if (isBrowser && !cfg.skipDataMain) {
        //Figure out baseUrl. Get it from the script tag with require.js in it.
        eachReverse(scripts(), function (script) {
            //Set the 'head' where we can append children by
            //using the script's parent.
            if (!head) {
                head = script.parentNode;
            }

            //Look for a data-main attribute to set main script for the page
            //to load. If it is there, the path to data main becomes the
            //baseUrl, if it is not already set.
            dataMain = script.getAttribute('data-main');
            if (dataMain) {
                //Preserve dataMain in case it is a path (i.e. contains '?')
                mainScript = dataMain;

                //Set final baseUrl if there is not already an explicit one,
                //but only do so if the data-main value is not a loader plugin
                //module ID.
                if (!cfg.baseUrl && mainScript.indexOf('!') === -1) {
                    //Pull off the directory of data-main for use as the
                    //baseUrl.
                    src = mainScript.split('/');
                    mainScript = src.pop();
                    subPath = src.length ? src.join('/')  + '/' : './';

                    cfg.baseUrl = subPath;
                }

                //Strip off any trailing .js since mainScript is now
                //like a module name.
                mainScript = mainScript.replace(jsSuffixRegExp, '');

                //If mainScript is still a path, fall back to dataMain
                if (req.jsExtRegExp.test(mainScript)) {
                    mainScript = dataMain;
                }

                //Put the data-main script in the files to load.
                cfg.deps = cfg.deps ? cfg.deps.concat(mainScript) : [mainScript];

                return true;
            }
        });
    }

    /**
     * The function that handles definitions of modules. Differs from
     * require() in that a string for the module should be the first argument,
     * and the function to execute after dependencies are loaded should
     * return a value to define the module corresponding to the first argument's
     * name.
     */
    define = function (name, deps, callback) {
        var node, context;

        //Allow for anonymous modules
        if (typeof name !== 'string') {
            //Adjust args appropriately
            callback = deps;
            deps = name;
            name = null;
        }

        //This module may not have dependencies
        if (!isArray(deps)) {
            callback = deps;
            deps = null;
        }

        //If no name, and callback is a function, then figure out if it a
        //CommonJS thing with dependencies.
        if (!deps && isFunction(callback)) {
            deps = [];
            //Remove comments from the callback string,
            //look for require calls, and pull them into the dependencies,
            //but only if there are function args.
            if (callback.length) {
                callback
                    .toString()
                    .replace(commentRegExp, commentReplace)
                    .replace(cjsRequireRegExp, function (match, dep) {
                        deps.push(dep);
                    });

                //May be a CommonJS thing even without require calls, but still
                //could use exports, and module. Avoid doing exports and module
                //work though if it just needs require.
                //REQUIRES the function to expect the CommonJS variables in the
                //order listed below.
                deps = (callback.length === 1 ? ['require'] : ['require', 'exports', 'module']).concat(deps);
            }
        }

        //If in IE 6-8 and hit an anonymous define() call, do the interactive
        //work.
        if (useInteractive) {
            node = currentlyAddingScript || getInteractiveScript();
            if (node) {
                if (!name) {
                    name = node.getAttribute('data-requiremodule');
                }
                context = contexts[node.getAttribute('data-requirecontext')];
            }
        }

        //Always save off evaluating the def call until the script onload handler.
        //This allows multiple modules to be in a file without prematurely
        //tracing dependencies, and allows for anonymous module support,
        //where the module name is not known until the script onload event
        //occurs. If no context, use the global queue, and get it processed
        //in the onscript load callback.
        if (context) {
            context.defQueue.push([name, deps, callback]);
            context.defQueueMap[name] = true;
        } else {
            globalDefQueue.push([name, deps, callback]);
        }
    };

    define.amd = {
        jQuery: true
    };

    /**
     * Executes the text. Normally just uses eval, but can be modified
     * to use a better, environment-specific call. Only used for transpiling
     * loader plugins, not for plain JS modules.
     * @param {String} text the text to execute/evaluate.
     */
    req.exec = function (text) {
        /*jslint evil: true */
        return eval(text);
    };

    //Set up with config info.
    req(cfg);
}(this));
",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "360c2017-2ecd-459a-f240-231bb375ad53"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
              "        <script>\n",
              "          requirejs.config({\n",
              "            paths: {\n",
              "              base: '/static/base',\n",
              "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
              "            },\n",
              "          });\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook focuses on **gold price forecasting** using a combination of baseline and deep learning models implemented in PyTorch. The project aims to predict future gold prices based on historical market data, enabling informed decision-making for trading and investment strategies.\n",
        "\n",
        "The workflow includes:\n",
        "\n",
        "* **Data Loading and Preprocessing**  Importing gold price data, applying statistical checks, scaling features, and generating technical indicators to enhance predictive power.\n",
        "* **Feature Engineering**  Leveraging rolling statistical tests and custom transformations to capture temporal dynamics in gold price movements.\n",
        "* **Model Development**  Implementing multiple architectures including:\n",
        "\n",
        "  * **Baseline Model**  A simple average-based predictor for performance benchmarking.\n",
        "  * **LSTM and GRU Networks**  Recurrent neural network models designed to capture sequential dependencies in time series data.\n",
        "* **Training and Evaluation**  Applying a structured training/testing regime, integrating techniques such as early stopping, and comparing model performances against the baseline.\n",
        "\n",
        "By establishing a robust comparison between naive prediction methods and advanced neural architectures, this notebook not only measures forecasting accuracy but also highlights the added value of deep learning for financial time series prediction.\n"
      ],
      "metadata": {
        "id": "8HWgI6bWS55c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMuRZfc26cgT",
        "outputId": "8c387934-60c3-4b82-9b38-88d266d73293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=d673f9afbdb01e48a3bc6a5a81181bf5c67d5aec79d58915660a7d83af70d668\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.5-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from ptflops) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->ptflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.2)\n",
            "Downloading ptflops-0.7.5-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.5\n"
          ]
        }
      ],
      "source": [
        " ! pip install ta\n",
        " ! pip install ptflops\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tteu6Rhk6HHi"
      },
      "source": [
        "# import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqHG44Kw6Cl2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from ptflops import get_model_complexity_info\n",
        "import math\n",
        "import seaborn as sns\n",
        "import ta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yHH7wOW6L31"
      },
      "source": [
        "# Load Data and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfp_h0Qm6UhS"
      },
      "outputs": [],
      "source": [
        "def rolling_adf(df, col, window_size=30):\n",
        "    \"\"\"\n",
        "    Calculate the Augmented Dickey-Fuller test statistic on a rolling window.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame containing the column on which to perform the ADF test.\n",
        "    col : str\n",
        "        The name of the column on which to perform the ADF test.\n",
        "    window_size : int\n",
        "        The size of the rolling window.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    df_copy : pandas.DataFrame\n",
        "        A new DataFrame with an additional column containing the rolling ADF test statistic.\n",
        "    \"\"\"\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Create an empty series to store rolling ADF test statistic\n",
        "    rolling_adf_stat = pd.Series(dtype='float64', index=df_copy.index)\n",
        "\n",
        "    # Loop through the DataFrame by `window_size` and apply `adfuller`.\n",
        "    for i in range(window_size, len(df)):\n",
        "        window = df_copy[col].iloc[i-window_size:i]\n",
        "        adf_result = adfuller(window)\n",
        "        adf_stat = adf_result[0]\n",
        "        rolling_adf_stat.at[df_copy.index[i]] = adf_stat\n",
        "\n",
        "    # Add the rolling ADF test statistic series to the original DataFrame\n",
        "    # df_copy['rolling_adf_stat'] = rolling_adf_stat\n",
        "\n",
        "    return rolling_adf_stat\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Kaufmans Adaptive Moving Average (KAMA)\n",
        "\n",
        "def kama(df, col, n):\n",
        "  df_copy = df.copy()\n",
        "  # df_copy[f'kama_{n}'] = ta.momentum.KAMAIndicator(df_copy[col], n).kama()\n",
        "  return ta.momentum.KAMAIndicator(df_copy[col], n).kama()\n",
        "\n",
        "def moving_parkinson_estimator(df, window_size=10):\n",
        "\n",
        "  def parkinson_estimator(df):\n",
        "    N = len(df)\n",
        "    sum_squared = np.sum(np.log(df['High'] / df['Low'])**2)\n",
        "    volatility = math.sqrt((1/(4 * N * math.log(2))) * sum_squared)\n",
        "    return volatility\n",
        "\n",
        "  df_copy = df.copy()\n",
        "\n",
        "  rolling_volatility = pd.Series(dtype='float64')\n",
        "\n",
        "  for i in range(window_size, len(df)):\n",
        "    window = df_copy.loc[df_copy.index[i-window_size] : df_copy.index[i]]\n",
        "    volatility = parkinson_estimator(window)\n",
        "    rolling_volatility.at[df_copy.index[i]] = volatility\n",
        "\n",
        "  # df_copy['rolling_volatility_parkinson'] = rolling_volatility\n",
        "\n",
        "  return rolling_volatility\n",
        "\n",
        "def moving_yang_zhang_estimator(df, window_size=30):\n",
        "    \"\"\"\n",
        "    Calculate Parkinson's volatility estimator based on high and low prices.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame containing 'high' and 'low' columns for each trading period.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    volatility : float\n",
        "        Estimated volatility based on Parkinson's method.\n",
        "    \"\"\"\n",
        "    def yang_zhang_estimator(df):\n",
        "        N = len(window)\n",
        "\n",
        "        term1 = np.log(window['High'] / window['Close']) * np.log(window['High'] / window['Open'])\n",
        "        term2 = np.log(window['Low'] / window['Close']) * np.log(window['Low'] / window['Open'])\n",
        "\n",
        "        sum_squared = np.sum(term1 + term2)\n",
        "        volatility = np.sqrt(sum_squared / N)\n",
        "\n",
        "        return volatility\n",
        "\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    rolling_volatility = pd.Series(dtype='float64')\n",
        "\n",
        "    for i in range(window_size, len(df)):\n",
        "        window = df_copy.loc[df_copy.index[i-window_size]: df_copy.index[i]]\n",
        "        volatility = yang_zhang_estimator(window)\n",
        "        rolling_volatility.at[df_copy.index[i]] = volatility\n",
        "\n",
        "\n",
        "    return rolling_volatility\n",
        "\n",
        "def RSI(df, col, window_size):\n",
        "  delta = df[col].diff(1)\n",
        "  positive = delta.copy()\n",
        "  negative = delta.copy()\n",
        "  positive[positive < 0] = 0\n",
        "  negative[negative > 0] = 0\n",
        "  average_gain = positive.rolling(window=window_size).mean()\n",
        "  average_loss = abs(negative.rolling(window=window_size).mean())\n",
        "  relative_strength = average_gain / average_loss\n",
        "  RSI = 100.0 - (100.0 - (1.0 + relative_strength))\n",
        "\n",
        "  return RSI\n",
        "\n",
        "\n",
        "def create_features(df, window_size=30):\n",
        "  df['moving_parkinson'] = moving_parkinson_estimator(df, window_size=window_size)\n",
        "  df['rolling_adf'] = rolling_adf(df, 'Price', window_size=window_size)\n",
        "  df['moving_yang_zhang'] = moving_yang_zhang_estimator(df, window_size=window_size)\n",
        "  df['kama'] =kama(df, 'Price', window_size)\n",
        "  df['rsi'] = RSI(df, 'Price', window_size)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_MonFxF6tIb"
      },
      "outputs": [],
      "source": [
        "pth = '/content/drive/MyDrive/data.xlsx'\n",
        "\n",
        "df = pd.read_excel(pth, header=1, sheet_name='Data')\n",
        "\n",
        "df['Timestamp'] = pd.to_timedelta(df['Day'], unit='d') + \\\n",
        "                pd.to_timedelta(df['Hour'], unit='h') + \\\n",
        "                pd.to_timedelta(df['Minute'], unit='m') + \\\n",
        "                pd.to_timedelta(df['Second'], unit='s')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df):\n",
        "  df1 = deepcopy(df)\n",
        "  z_scores = (df1['Price.'] - df1['Price.'].mean()) / df1['Price.'].std()\n",
        "\n",
        "  # Filter out rows where |z| > 2\n",
        "  df_no_outliers = df1[np.abs(z_scores) <= 2.0]\n",
        "\n",
        "  # Optional: reset index\n",
        "  df_no_outliers = df_no_outliers.reset_index()\n",
        "\n",
        "  return df_no_outliers\n",
        "\n",
        "\n",
        "\n",
        "df_no_outliers = remove_outliers(df)"
      ],
      "metadata": {
        "id": "Dn1IqKe37fHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 1)\n",
        "axs[0].plot(df['Price.'])\n",
        "axs[1].plot(df_no_outliers['Price.'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "bYJITXDTyXHB",
        "outputId": "b48e1df2-c8d4-4c7a-fd36-b7d48a8ca035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a84fd3ff890>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8wfPXVX6J_z"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsjTYESI04kF"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise:\n",
        "    def __init__(self):\n",
        "        self.noise_std = random.uniform(0, 0.005)\n",
        "    def __call__(self, x):\n",
        "        noise = torch.randn_like(x) * self.noise_std * x\n",
        "        return x + noise\n",
        "\n",
        "class RandomScaling:\n",
        "    def __init__(self, scale_range=(0.995, 1.005)):\n",
        "        self.scale_range = scale_range\n",
        "    def __call__(self, x):\n",
        "        scale = np.random.uniform(*self.scale_range)\n",
        "        return x * scale\n",
        "\n",
        "class Compose:\n",
        "    \"\"\"Chain multiple augmentations.\"\"\"\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "    def __call__(self, x):\n",
        "        for t in self.transforms:\n",
        "            x = t(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9AWmTzW6Lae"
      },
      "outputs": [],
      "source": [
        "class GoldDataset(Dataset):\n",
        "\n",
        "  def __init__(self, dataset, lookback, transform=None):\n",
        "\n",
        "    self.transform = transform\n",
        "    self.dataset = dataset\n",
        "    self.lookback = lookback\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    data = self.transform(self.dataset[idx]) if self.transform else self.dataset[idx]\n",
        "\n",
        "    x = data[:self.lookback].unsqueeze(-1)\n",
        "    y = data[self.lookback:]\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSar_zTr8X0y"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "def get_loaders(dataframe, time_bin, scaler, lookback, lookforward,batch_size: int, train_size:float,  transform=None):\n",
        "\n",
        "    dataframe['TimeBin'] = df['Timestamp'].dt.floor(f'{time_bin}min')\n",
        "    grouped_df = dataframe.groupby('TimeBin').agg(\n",
        "                Price = ('Price.', 'mean'))\n",
        "    lookforward -= 1\n",
        "\n",
        "    grouped_df['ScaledPrice'] = scaler.fit_transform(grouped_df[['Price']])\n",
        "\n",
        "    for i in range((lookback+lookforward), 0, -1):\n",
        "\n",
        "      grouped_df[f'price_lag_{i}'] = grouped_df['ScaledPrice'].shift(i)\n",
        "\n",
        "    grouped_df.dropna(inplace=True)\n",
        "\n",
        "    lag_cols = [f'price_lag_{i}' for i in range(lookback+lookforward, 0, -1)]\n",
        "    lag_cols.append('ScaledPrice')\n",
        "\n",
        "    data = torch.tensor(grouped_df[lag_cols].values, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    index = int(len(grouped_df) * train_size)\n",
        "\n",
        "    train_raw = data[:index, :]\n",
        "    test_raw = data[index:, :]\n",
        "\n",
        "    trainset = GoldDataset(train_raw, lookback, transform)\n",
        "    testset = GoldDataset(test_raw, lookback, None)\n",
        "\n",
        "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return trainset, train_loader, testset, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKjGBmkY7-m7"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "  def __init__(self, sample_mean=3):\n",
        "\n",
        "    super().__init__()\n",
        "    self.sample_mean = sample_mean\n",
        "\n",
        "  def forward(self, x):\n",
        "    last_samples = x[:, -self.sample_mean:, :]   # shape: [batch, 2, 1]\n",
        "    return last_samples.mean(dim=1)"
      ],
      "metadata": {
        "id": "OO4lvKmeFkDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vp1OQNz6iIw"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_stacked_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_stacked_layers = num_stacked_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvlZWAeQ0d3e"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_stacked_layers, output_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_stacked_layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_stacked_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_stacked_layers > 1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, C]\n",
        "        B = x.size(0)\n",
        "        h0 = torch.zeros(self.num_layers, B, self.hidden_size, device=x.device)\n",
        "        out, _ = self.gru(x, h0)     # out: [B, T, H]\n",
        "        out = out[:, -1, :]          # last timestep\n",
        "        out = self.fc(out)           # [B, output_size]\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lqj166D06lE"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)                  # [T, D]\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)    # [T, 1]\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)  # not a parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, D]\n",
        "        T = x.size(1)\n",
        "        return x + self.pe[:T].unsqueeze(0)   # broadcast to [B, T, D]\n",
        "\n",
        "class TransformerTS(nn.Module):\n",
        "    \"\"\"\n",
        "    Projects input_size -> d_model, adds positional encoding,\n",
        "    passes through TransformerEncoder, takes last timestep, then a head.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 num_encoder_layers,\n",
        "                 dim_feedforward,\n",
        "                 output_size,\n",
        "                 dropout=0.1,\n",
        "                 layer_norm_eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_size, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_encoder_layers,\n",
        "            norm=nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, src_key_padding_mask=None):\n",
        "        # x: [B, T, C]\n",
        "        x = self.input_proj(x)            # [B, T, D]\n",
        "        x = self.pos_enc(x)               # [B, T, D]\n",
        "        # src_key_padding_mask: [B, T] with True for PAD positions (optional)\n",
        "        h = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # [B, T, D]\n",
        "        h_last = h[:, -1, :]              # last timestep representation\n",
        "        out = self.head(h_last)           # [B, output_size]\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51tGBmNs8CG7"
      },
      "source": [
        "# training & test regime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzKs_3miAgc_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0, mode='min', verbose=False, save_path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        patience : int         # how many epochs to wait without improvement\n",
        "        min_delta : float      # minimum change to count as an improvement\n",
        "        mode : 'max' | 'min'   # 'max' for accuracy, 'min' for loss\n",
        "        verbose : bool         # print messages when improvement happens\n",
        "        save_path : str        # path to save the best model\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.mode = mode\n",
        "        self.verbose = verbose\n",
        "        self.save_path = save_path\n",
        "\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_best = np.inf if mode == 'min' else -np.inf\n",
        "\n",
        "    def __call__(self, val_metric, model):\n",
        "        score = val_metric\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            if self.best_score is None:\n",
        "                self.best_score = score\n",
        "                self.save_checkpoint(model)\n",
        "            elif score > self.best_score - self.min_delta:\n",
        "                self.counter += 1\n",
        "                if self.verbose:\n",
        "                    print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "                if self.counter >= self.patience:\n",
        "                    self.early_stop = True\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.save_checkpoint(model)\n",
        "                self.counter = 0\n",
        "        else:  # mode == 'max'\n",
        "            if self.best_score is None:\n",
        "                self.best_score = score\n",
        "                self.save_checkpoint(model)\n",
        "            elif score < self.best_score + self.min_delta:\n",
        "                self.counter += 1\n",
        "                if self.verbose:\n",
        "                    print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "                if self.counter >= self.patience:\n",
        "                    self.early_stop = True\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.save_checkpoint(model)\n",
        "                self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        \"\"\"Saves model when validation metric improves.\"\"\"\n",
        "        torch.save(model.state_dict(), self.save_path)\n",
        "        if self.verbose:\n",
        "            print(f\"Model improved. Saving model to {self.save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PjYtPD18BgK"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, show=True):\n",
        "\n",
        "    model.train(True)\n",
        "\n",
        "    if show:\n",
        "      print(f'Epoch: {epoch + 1}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_index, batch in enumerate(train_loader):\n",
        "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
        "        output = model(x_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_index % 100 == 99:  # print every 100 batches\n",
        "            avg_loss_across_batches = running_loss / 100\n",
        "            if show:\n",
        "              print('Batch {0}, Loss: {1:.3f}'.format(batch_index+1,\n",
        "                                                    avg_loss_across_batches))\n",
        "            running_loss = 0.0\n",
        "    if show:\n",
        "      print()\n",
        "\n",
        "def validate_one_epoch(model,early_stopping, show=True):\n",
        "    model.train(False)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_index, batch in enumerate(test_loader):\n",
        "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x_batch)\n",
        "            loss = loss_function(output, y_batch)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    avg_loss_across_batches = running_loss / len(test_loader)\n",
        "    early_stopping(avg_loss_across_batches, model)\n",
        "\n",
        "\n",
        "    if show:\n",
        "      print('Val Loss: {0:.5f}'.format(avg_loss_across_batches))\n",
        "      print('***************************************************')\n",
        "      print()\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "      return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWLksV-tKKRC"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OXYXinKPqH"
      },
      "outputs": [],
      "source": [
        "def _mae(y, yhat):\n",
        "    return np.mean(np.abs(y - yhat))\n",
        "\n",
        "def _rmse(y, yhat):\n",
        "    return np.sqrt(np.mean((y - yhat) ** 2))\n",
        "\n",
        "def _mape(y, yhat, eps=1e-8):\n",
        "    denom = np.maximum(np.abs(y), eps)\n",
        "    return 100.0 * np.mean(np.abs((y - yhat) / denom))\n",
        "\n",
        "def _smape(y, yhat, eps=1e-8):\n",
        "    denom = np.maximum((np.abs(y) + np.abs(yhat)) / 2.0, eps)\n",
        "    return 100.0 * np.mean(np.abs(y - yhat) / denom)\n",
        "\n",
        "def _r2(y, yhat):\n",
        "    ss_res = np.sum((y - yhat) ** 2)\n",
        "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
        "    return 1.0 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
        "\n",
        "def _mase(y_insample, y_insample_naive, y, yhat, eps=1e-12):\n",
        "    \"\"\"\n",
        "    y_insample: series used to compute naive scale (e.g., train_true[1:])\n",
        "    y_insample_naive: naive preds for insample (e.g., train_true[:-1])\n",
        "    MASE = MAE(model)/MAE(naive) using in-sample naive MAE as the scale.\n",
        "    \"\"\"\n",
        "    scale = _mae(y_insample, y_insample_naive)\n",
        "    return _mae(y, yhat) / (scale + eps)\n",
        "\n",
        "def evaluate_forecast(out_dict, horizon_step=0):\n",
        "\n",
        "    def select_step(arr):\n",
        "      if arr.ndim == 2:\n",
        "          return arr[:, horizon_step]\n",
        "      return arr\n",
        "\n",
        "    train_pred = select_step(out_dict[\"train_pred_inv\"])\n",
        "    train_true = select_step(out_dict[\"train_true_inv\"])\n",
        "    test_pred  = select_step(out_dict[\"test_pred_inv\"])\n",
        "    test_true  = select_step(out_dict[\"test_true_inv\"])\n",
        "    # ensure 1D & drop NaNs if any\n",
        "    def _clean(a):\n",
        "        a = np.asarray(a).reshape(-1)\n",
        "        return a[~np.isnan(a)]\n",
        "    train_true = _clean(train_true); train_pred = _clean(train_pred)\n",
        "    test_true  = _clean(test_true);  test_pred  = _clean(test_pred)\n",
        "\n",
        "    # In-sample naive (one-step) for MASE scale: y_{t-1}\n",
        "    # Align lengths: compare train_true[1:] vs naive = train_true[:-1]\n",
        "    if len(train_true) >= 2:\n",
        "        insample_y = train_true[1:]\n",
        "        insample_naive = train_true[:-1]\n",
        "        mase_train = _mase(insample_y, insample_naive, train_true, train_pred)\n",
        "        mase_test  = _mase(insample_y, insample_naive, test_true,  test_pred)\n",
        "    else:\n",
        "        mase_train = np.nan\n",
        "        mase_test  = np.nan\n",
        "\n",
        "    metrics_train = {\n",
        "        \"MAE\":  _mae(train_true, train_pred),\n",
        "        \"RMSE\": _rmse(train_true, train_pred),\n",
        "        \"MAPE\": _mape(train_true, train_pred),\n",
        "        \"sMAPE\": _smape(train_true, train_pred),\n",
        "        \"R2\":   _r2(train_true, train_pred),\n",
        "        \"MASE\": mase_train,\n",
        "    }\n",
        "    metrics_test = {\n",
        "        \"MAE\":  _mae(test_true, test_pred),\n",
        "        \"RMSE\": _rmse(test_true, test_pred),\n",
        "        \"MAPE\": _mape(test_true, test_pred),\n",
        "        \"sMAPE\": _smape(test_true, test_pred),\n",
        "        \"R2\":   _r2(test_true, test_pred),\n",
        "        \"MASE\": mase_test,\n",
        "    }\n",
        "    return {\"train\": metrics_train, \"test\": metrics_test}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jht49w2-Wdf_"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def _predict_on_loader(model, loader, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    preds, trues = [], []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)                 # [B, lookback, 1]\n",
        "        y = y.to(device)                 # [B, horizon]\n",
        "        out = model(x)                   # expect [B, horizon] (or [B, horizon, 1] -> squeeze)\n",
        "        if out.dim() == 3 and out.size(-1) == 1:\n",
        "            out = out.squeeze(-1)\n",
        "        preds.append(out.detach().cpu())\n",
        "        trues.append(y.detach().cpu())\n",
        "\n",
        "    return torch.cat(preds, dim=0), torch.cat(trues, dim=0)  # [N, horizon], [N, horizon]\n",
        "\n",
        "def _inverse_scale_2d(arr_2d, scaler):\n",
        "    \"\"\"\n",
        "    arr_2d: numpy array [N, H] in scaler space.\n",
        "    scaler: fitted MinMaxScaler on price column.\n",
        "    \"\"\"\n",
        "    flat = arr_2d.reshape(-1, 1)\n",
        "    inv = scaler.inverse_transform(flat)\n",
        "    return inv.reshape(arr_2d.shape)\n",
        "\n",
        "def predict_train_test(\n",
        "    model,\n",
        "    trainset,\n",
        "    testset,\n",
        "    batch_size=256,\n",
        "    device=None,\n",
        "    scaler=None,          # pass if you want inverse-scaled outputs\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns a dict with predictions and targets for train and test.\n",
        "    Shapes are [N, horizon] for both preds and targets.\n",
        "    If `scaler` is provided, adds *_inv with inverse-scaled prices.\n",
        "    \"\"\"\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=False,\n",
        "                              num_workers=num_workers, pin_memory=pin_memory, drop_last=False)\n",
        "    test_loader  = DataLoader(testset,  batch_size=batch_size, shuffle=False,\n",
        "                              num_workers=num_workers, pin_memory=pin_memory, drop_last=False)\n",
        "\n",
        "    train_pred, train_true = _predict_on_loader(model, train_loader, device)\n",
        "    test_pred,  test_true  = _predict_on_loader(model, test_loader,  device)\n",
        "\n",
        "    out = {\n",
        "        \"train_pred\": train_pred.numpy(),   # scaled\n",
        "        \"train_true\": train_true.numpy(),\n",
        "        \"test_pred\":  test_pred.numpy(),\n",
        "        \"test_true\":  test_true.numpy(),\n",
        "    }\n",
        "\n",
        "    if scaler is not None:\n",
        "        out[\"train_pred_inv\"] = _inverse_scale_2d(out[\"train_pred\"], scaler)\n",
        "        out[\"train_true_inv\"] = _inverse_scale_2d(out[\"train_true\"], scaler)\n",
        "        out[\"test_pred_inv\"]  = _inverse_scale_2d(out[\"test_pred\"],  scaler)\n",
        "        out[\"test_true_inv\"]  = _inverse_scale_2d(out[\"test_true\"],  scaler)\n",
        "\n",
        "\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdnp5LgEIC2J"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_predictions_plotly(out_dict, horizon_step=0, title=\"Prediction vs Actual (Train/Test)\"):\n",
        "    \"\"\"\n",
        "    out_dict: dictionary with keys:\n",
        "      train_pred_inv, train_true_inv, test_pred_inv, test_true_inv\n",
        "      Each should be numpy arrays [N, H] or [N] if single step\n",
        "    horizon_step: which forecast step to plot (0 = next step)\n",
        "    \"\"\"\n",
        "\n",
        "    # pick correct horizon step\n",
        "    def select_step(arr):\n",
        "        if arr.ndim == 2:\n",
        "            return arr[:, horizon_step]\n",
        "        return arr\n",
        "\n",
        "    train_pred = select_step(out_dict[\"train_pred_inv\"])\n",
        "    train_true = select_step(out_dict[\"train_true_inv\"])\n",
        "    test_pred  = select_step(out_dict[\"test_pred_inv\"])\n",
        "    test_true  = select_step(out_dict[\"test_true_inv\"])\n",
        "\n",
        "    n_train = len(train_pred)\n",
        "    n_test  = len(test_pred)\n",
        "\n",
        "    # x axes\n",
        "    x_train = list(range(n_train))\n",
        "    x_test  = list(range(n_train, n_train + n_test))\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Train actual\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x_train, y=train_true,\n",
        "        mode='lines', name='Train Actual',\n",
        "        line=dict(color='blue')\n",
        "    ))\n",
        "\n",
        "    # Train prediction\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x_train, y=train_pred,\n",
        "        mode='lines', name='Train Pred',\n",
        "        line=dict(color='blue', dash='dash')\n",
        "    ))\n",
        "\n",
        "    # Test actual\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x_test, y=test_true,\n",
        "        mode='lines', name='Test Actual',\n",
        "        line=dict(color='orange')\n",
        "    ))\n",
        "\n",
        "    # Test prediction\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x_test, y=test_pred,\n",
        "        mode='lines', name='Test Pred',\n",
        "        line=dict(color='orange', dash='dash')\n",
        "    ))\n",
        "\n",
        "    # vertical line for train/test split\n",
        "    fig.add_vline(\n",
        "        x=n_train - 0.5,\n",
        "        line_width=2, line_dash=\"dot\", line_color=\"black\"\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis_title=\"Sample Index (time ordered)\",\n",
        "        yaxis_title=\"Price\",\n",
        "        legend=dict(x=0, y=1),\n",
        "        hovermode=\"x unified\",\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9OWAs-oL0kk"
      },
      "outputs": [],
      "source": [
        "def plot_test_predictions_plotly(\n",
        "    results,\n",
        "    horizon_step: int = 0,\n",
        "    title: str = \"Prediction vs Actual (Test Only)\"\n",
        "):\n",
        "    \"\"\"\n",
        "    results: dict with structure\n",
        "        {\n",
        "            \"test_true_inv\": np.ndarray [N] or [N, H],\n",
        "            \"preds\": {\n",
        "                \"LSTM\": np.ndarray [N] or [N, H],\n",
        "                \"GRU\":  np.ndarray [N] or [N, H],\n",
        "                \"Transformer\": np.ndarray [N] or [N, H],\n",
        "                ...\n",
        "            }\n",
        "        }\n",
        "    horizon_step: which forecast step to plot (0 = next step)\n",
        "    \"\"\"\n",
        "\n",
        "    def select_step(arr):\n",
        "        # Accept shape [N] or [N, H]\n",
        "        if arr.ndim == 2:\n",
        "            if horizon_step < 0 or horizon_step >= arr.shape[1]:\n",
        "                raise ValueError(f\"horizon_step {horizon_step} out of range for array with shape {arr.shape}.\")\n",
        "            return arr[:, horizon_step]\n",
        "        return arr\n",
        "\n",
        "    # Extract and validate y_true\n",
        "    if \"test_true_inv\" not in results or \"preds\" not in results:\n",
        "        raise KeyError('Expected keys: \"test_true_inv\" and \"preds\" in results.')\n",
        "\n",
        "    y_true_full = np.asarray(results[\"test_true_inv\"])\n",
        "    y_true = select_step(y_true_full)\n",
        "    N = len(y_true)\n",
        "\n",
        "    # Prepare x axis (test indices only)\n",
        "    x = np.arange(N)\n",
        "\n",
        "    # Build figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Actual test series (solid line)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x, y=y_true,\n",
        "        mode=\"lines\",\n",
        "        name=\"Test Actual\",\n",
        "        line=dict(color=\"black\")\n",
        "    ))\n",
        "\n",
        "    # Add one dashed line per model\n",
        "    for model_name, y_pred_full in results[\"preds\"].items():\n",
        "        y_pred = select_step(np.asarray(y_pred_full))\n",
        "\n",
        "        if len(y_pred) != N:\n",
        "            raise ValueError(\n",
        "                f'Length mismatch for \"{model_name}\": got {len(y_pred)} vs y_true length {N}.'\n",
        "            )\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=x, y=y_pred,\n",
        "            mode=\"lines\",\n",
        "            name=f\"{model_name} Pred\",\n",
        "            line=dict(dash=\"dash\")  # color auto-cycles\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis_title=\"Test Sample Index (time ordered)\",\n",
        "        yaxis_title=\"Price\",\n",
        "        legend=dict(x=0, y=1),\n",
        "        hovermode=\"x unified\",\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvLAQbHGyHIQ"
      },
      "source": [
        "# Concat all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvb1VaCsyQw6"
      },
      "outputs": [],
      "source": [
        "augmentations = Compose([AddGaussianNoise()])#, RandomScaling()])\n",
        "\n",
        "trainset, train_loader, testset, test_loader = get_loaders(df_no_outliers, time_bin=60, scaler=scaler, lookback=12,\n",
        "                                        lookforward=1, batch_size=8, train_size=0.9,\n",
        "                                        transform=augmentations)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 200\n",
        "input_size=1\n",
        "d_model=128\n",
        "nhead=8\n",
        "num_encoder_layers=1\n",
        "dim_feedforward=64\n",
        "output_size=1\n",
        "dropout=0.1"
      ],
      "metadata": {
        "id": "QqKKnKl56CJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0yyg3gsySEq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(patience=50, mode='min', verbose=False, save_path='/content/checkpoint_transformer.pt')\n",
        "\n",
        "\n",
        "model = TransformerTS(\n",
        "    input_size=input_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    output_size=output_size,\n",
        "    dropout=dropout)\n",
        "\n",
        "# model = GRUModel(1, 4, 1, 1)\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, show=False)\n",
        "    stop_criteria = validate_one_epoch(model, early_stopping)\n",
        "\n",
        "    if stop_criteria:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtHiKv5A-kfM"
      },
      "source": [
        "# Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 1\n",
        "output_size = 1\n",
        "num_hidden_layers = 4\n",
        "num_stacked_layers = 1\n",
        "patience = 30\n",
        "num_epochs = 5000\n",
        "learning_rate = 0.0005"
      ],
      "metadata": {
        "id": "f4H-tZb0wdrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB3twgcd-nal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9825efef-fc2a-4615-a6bf-784152132f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.00408\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00356\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00457\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00413\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00511\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00425\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00434\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00435\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00428\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00394\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00377\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00420\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00399\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00361\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00384\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00402\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00446\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00362\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00392\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00370\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00381\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00345\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00348\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00349\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00405\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00460\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00372\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00379\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00351\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00439\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00394\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00423\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00371\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00383\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00309\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00280\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00354\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00406\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00357\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00334\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00344\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00410\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00389\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00322\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00410\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00353\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00364\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00384\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00347\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00453\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00362\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00349\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00371\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00416\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00428\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00409\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00327\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00381\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00358\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00332\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00445\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00369\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00322\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00401\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00395\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00319\n",
            "***************************************************\n",
            "\n",
            "Early stopping triggered\n"
          ]
        }
      ],
      "source": [
        "# train LSTM\n",
        "lstm_model = LSTM(input_size, num_hidden_layers, num_stacked_layers, output_size)\n",
        "\n",
        "lstm_model.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
        "early_stopping = EarlyStopping(patience=patience, mode='min', verbose=False, save_path='/content/checkpoint_lstm.pt')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(lstm_model, show=False)\n",
        "\n",
        "    stop_criteria = validate_one_epoch(lstm_model, early_stopping)\n",
        "\n",
        "    if stop_criteria:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnpSfTEE_XHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7c882111-1c0b-466e-c457-c59f3138d223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "\n",
            "Val Loss: 1.00405\n",
            "***************************************************\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Val Loss: 0.75313\n",
            "***************************************************\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Val Loss: 0.53319\n",
            "***************************************************\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Val Loss: 0.36551\n",
            "***************************************************\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "Val Loss: 0.25250\n",
            "***************************************************\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Val Loss: 0.18785\n",
            "***************************************************\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Val Loss: 0.15519\n",
            "***************************************************\n",
            "\n",
            "Epoch: 8\n",
            "\n",
            "Val Loss: 0.13744\n",
            "***************************************************\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "Val Loss: 0.12689\n",
            "***************************************************\n",
            "\n",
            "Epoch: 10\n",
            "\n",
            "Val Loss: 0.11706\n",
            "***************************************************\n",
            "\n",
            "Epoch: 11\n",
            "\n",
            "Val Loss: 0.11144\n",
            "***************************************************\n",
            "\n",
            "Epoch: 12\n",
            "\n",
            "Val Loss: 0.10242\n",
            "***************************************************\n",
            "\n",
            "Epoch: 13\n",
            "\n",
            "Val Loss: 0.09784\n",
            "***************************************************\n",
            "\n",
            "Epoch: 14\n",
            "\n",
            "Val Loss: 0.09155\n",
            "***************************************************\n",
            "\n",
            "Epoch: 15\n",
            "\n",
            "Val Loss: 0.08592\n",
            "***************************************************\n",
            "\n",
            "Epoch: 16\n",
            "\n",
            "Val Loss: 0.08139\n",
            "***************************************************\n",
            "\n",
            "Epoch: 17\n",
            "\n",
            "Val Loss: 0.07861\n",
            "***************************************************\n",
            "\n",
            "Epoch: 18\n",
            "\n",
            "Val Loss: 0.07440\n",
            "***************************************************\n",
            "\n",
            "Epoch: 19\n",
            "\n",
            "Val Loss: 0.07065\n",
            "***************************************************\n",
            "\n",
            "Epoch: 20\n",
            "\n",
            "Val Loss: 0.06725\n",
            "***************************************************\n",
            "\n",
            "Epoch: 21\n",
            "\n",
            "Val Loss: 0.06436\n",
            "***************************************************\n",
            "\n",
            "Epoch: 22\n",
            "\n",
            "Val Loss: 0.06234\n",
            "***************************************************\n",
            "\n",
            "Epoch: 23\n",
            "\n",
            "Val Loss: 0.05935\n",
            "***************************************************\n",
            "\n",
            "Epoch: 24\n",
            "\n",
            "Val Loss: 0.05583\n",
            "***************************************************\n",
            "\n",
            "Epoch: 25\n",
            "\n",
            "Val Loss: 0.05475\n",
            "***************************************************\n",
            "\n",
            "Epoch: 26\n",
            "\n",
            "Val Loss: 0.05185\n",
            "***************************************************\n",
            "\n",
            "Epoch: 27\n",
            "\n",
            "Val Loss: 0.04995\n",
            "***************************************************\n",
            "\n",
            "Epoch: 28\n",
            "\n",
            "Val Loss: 0.04824\n",
            "***************************************************\n",
            "\n",
            "Epoch: 29\n",
            "\n",
            "Val Loss: 0.04749\n",
            "***************************************************\n",
            "\n",
            "Epoch: 30\n",
            "\n",
            "Val Loss: 0.04555\n",
            "***************************************************\n",
            "\n",
            "Epoch: 31\n",
            "\n",
            "Val Loss: 0.04439\n",
            "***************************************************\n",
            "\n",
            "Epoch: 32\n",
            "\n",
            "Val Loss: 0.04177\n",
            "***************************************************\n",
            "\n",
            "Epoch: 33\n",
            "\n",
            "Val Loss: 0.04130\n",
            "***************************************************\n",
            "\n",
            "Epoch: 34\n",
            "\n",
            "Val Loss: 0.03887\n",
            "***************************************************\n",
            "\n",
            "Epoch: 35\n",
            "\n",
            "Val Loss: 0.03850\n",
            "***************************************************\n",
            "\n",
            "Epoch: 36\n",
            "\n",
            "Val Loss: 0.03617\n",
            "***************************************************\n",
            "\n",
            "Epoch: 37\n",
            "\n",
            "Val Loss: 0.03563\n",
            "***************************************************\n",
            "\n",
            "Epoch: 38\n",
            "\n",
            "Val Loss: 0.03456\n",
            "***************************************************\n",
            "\n",
            "Epoch: 39\n",
            "\n",
            "Val Loss: 0.03204\n",
            "***************************************************\n",
            "\n",
            "Epoch: 40\n",
            "\n",
            "Val Loss: 0.03252\n",
            "***************************************************\n",
            "\n",
            "Epoch: 41\n",
            "\n",
            "Val Loss: 0.03209\n",
            "***************************************************\n",
            "\n",
            "Epoch: 42\n",
            "\n",
            "Val Loss: 0.03005\n",
            "***************************************************\n",
            "\n",
            "Epoch: 43\n",
            "\n",
            "Val Loss: 0.02869\n",
            "***************************************************\n",
            "\n",
            "Epoch: 44\n",
            "\n",
            "Val Loss: 0.02758\n",
            "***************************************************\n",
            "\n",
            "Epoch: 45\n",
            "\n",
            "Val Loss: 0.02831\n",
            "***************************************************\n",
            "\n",
            "Epoch: 46\n",
            "\n",
            "Val Loss: 0.02732\n",
            "***************************************************\n",
            "\n",
            "Epoch: 47\n",
            "\n",
            "Val Loss: 0.02539\n",
            "***************************************************\n",
            "\n",
            "Epoch: 48\n",
            "\n",
            "Val Loss: 0.02554\n",
            "***************************************************\n",
            "\n",
            "Epoch: 49\n",
            "\n",
            "Val Loss: 0.02469\n",
            "***************************************************\n",
            "\n",
            "Epoch: 50\n",
            "\n",
            "Val Loss: 0.02377\n",
            "***************************************************\n",
            "\n",
            "Epoch: 51\n",
            "\n",
            "Val Loss: 0.02224\n",
            "***************************************************\n",
            "\n",
            "Epoch: 52\n",
            "\n",
            "Val Loss: 0.02250\n",
            "***************************************************\n",
            "\n",
            "Epoch: 53\n",
            "\n",
            "Val Loss: 0.02124\n",
            "***************************************************\n",
            "\n",
            "Epoch: 54\n",
            "\n",
            "Val Loss: 0.02160\n",
            "***************************************************\n",
            "\n",
            "Epoch: 55\n",
            "\n",
            "Val Loss: 0.02212\n",
            "***************************************************\n",
            "\n",
            "Epoch: 56\n",
            "\n",
            "Val Loss: 0.02148\n",
            "***************************************************\n",
            "\n",
            "Epoch: 57\n",
            "\n",
            "Val Loss: 0.02022\n",
            "***************************************************\n",
            "\n",
            "Epoch: 58\n",
            "\n",
            "Val Loss: 0.01856\n",
            "***************************************************\n",
            "\n",
            "Epoch: 59\n",
            "\n",
            "Val Loss: 0.01864\n",
            "***************************************************\n",
            "\n",
            "Epoch: 60\n",
            "\n",
            "Val Loss: 0.01712\n",
            "***************************************************\n",
            "\n",
            "Epoch: 61\n",
            "\n",
            "Val Loss: 0.01836\n",
            "***************************************************\n",
            "\n",
            "Epoch: 62\n",
            "\n",
            "Val Loss: 0.01885\n",
            "***************************************************\n",
            "\n",
            "Epoch: 63\n",
            "\n",
            "Val Loss: 0.01704\n",
            "***************************************************\n",
            "\n",
            "Epoch: 64\n",
            "\n",
            "Val Loss: 0.01662\n",
            "***************************************************\n",
            "\n",
            "Epoch: 65\n",
            "\n",
            "Val Loss: 0.01530\n",
            "***************************************************\n",
            "\n",
            "Epoch: 66\n",
            "\n",
            "Val Loss: 0.01724\n",
            "***************************************************\n",
            "\n",
            "Epoch: 67\n",
            "\n",
            "Val Loss: 0.01598\n",
            "***************************************************\n",
            "\n",
            "Epoch: 68\n",
            "\n",
            "Val Loss: 0.01614\n",
            "***************************************************\n",
            "\n",
            "Epoch: 69\n",
            "\n",
            "Val Loss: 0.01422\n",
            "***************************************************\n",
            "\n",
            "Epoch: 70\n",
            "\n",
            "Val Loss: 0.01464\n",
            "***************************************************\n",
            "\n",
            "Epoch: 71\n",
            "\n",
            "Val Loss: 0.01478\n",
            "***************************************************\n",
            "\n",
            "Epoch: 72\n",
            "\n",
            "Val Loss: 0.01297\n",
            "***************************************************\n",
            "\n",
            "Epoch: 73\n",
            "\n",
            "Val Loss: 0.01425\n",
            "***************************************************\n",
            "\n",
            "Epoch: 74\n",
            "\n",
            "Val Loss: 0.01291\n",
            "***************************************************\n",
            "\n",
            "Epoch: 75\n",
            "\n",
            "Val Loss: 0.01251\n",
            "***************************************************\n",
            "\n",
            "Epoch: 76\n",
            "\n",
            "Val Loss: 0.01274\n",
            "***************************************************\n",
            "\n",
            "Epoch: 77\n",
            "\n",
            "Val Loss: 0.01306\n",
            "***************************************************\n",
            "\n",
            "Epoch: 78\n",
            "\n",
            "Val Loss: 0.01201\n",
            "***************************************************\n",
            "\n",
            "Epoch: 79\n",
            "\n",
            "Val Loss: 0.01211\n",
            "***************************************************\n",
            "\n",
            "Epoch: 80\n",
            "\n",
            "Val Loss: 0.01110\n",
            "***************************************************\n",
            "\n",
            "Epoch: 81\n",
            "\n",
            "Val Loss: 0.01057\n",
            "***************************************************\n",
            "\n",
            "Epoch: 82\n",
            "\n",
            "Val Loss: 0.01164\n",
            "***************************************************\n",
            "\n",
            "Epoch: 83\n",
            "\n",
            "Val Loss: 0.00967\n",
            "***************************************************\n",
            "\n",
            "Epoch: 84\n",
            "\n",
            "Val Loss: 0.01056\n",
            "***************************************************\n",
            "\n",
            "Epoch: 85\n",
            "\n",
            "Val Loss: 0.01081\n",
            "***************************************************\n",
            "\n",
            "Epoch: 86\n",
            "\n",
            "Val Loss: 0.01080\n",
            "***************************************************\n",
            "\n",
            "Epoch: 87\n",
            "\n",
            "Val Loss: 0.01029\n",
            "***************************************************\n",
            "\n",
            "Epoch: 88\n",
            "\n",
            "Val Loss: 0.01114\n",
            "***************************************************\n",
            "\n",
            "Epoch: 89\n",
            "\n",
            "Val Loss: 0.00937\n",
            "***************************************************\n",
            "\n",
            "Epoch: 90\n",
            "\n",
            "Val Loss: 0.01008\n",
            "***************************************************\n",
            "\n",
            "Epoch: 91\n",
            "\n",
            "Val Loss: 0.00876\n",
            "***************************************************\n",
            "\n",
            "Epoch: 92\n",
            "\n",
            "Val Loss: 0.00827\n",
            "***************************************************\n",
            "\n",
            "Epoch: 93\n",
            "\n",
            "Val Loss: 0.00888\n",
            "***************************************************\n",
            "\n",
            "Epoch: 94\n",
            "\n",
            "Val Loss: 0.01093\n",
            "***************************************************\n",
            "\n",
            "Epoch: 95\n",
            "\n",
            "Val Loss: 0.00815\n",
            "***************************************************\n",
            "\n",
            "Epoch: 96\n",
            "\n",
            "Val Loss: 0.00887\n",
            "***************************************************\n",
            "\n",
            "Epoch: 97\n",
            "\n",
            "Val Loss: 0.00744\n",
            "***************************************************\n",
            "\n",
            "Epoch: 98\n",
            "\n",
            "Val Loss: 0.00843\n",
            "***************************************************\n",
            "\n",
            "Epoch: 99\n",
            "\n",
            "Val Loss: 0.00787\n",
            "***************************************************\n",
            "\n",
            "Epoch: 100\n",
            "\n",
            "Val Loss: 0.00868\n",
            "***************************************************\n",
            "\n",
            "Epoch: 101\n",
            "\n",
            "Val Loss: 0.00884\n",
            "***************************************************\n",
            "\n",
            "Epoch: 102\n",
            "\n",
            "Val Loss: 0.00743\n",
            "***************************************************\n",
            "\n",
            "Epoch: 103\n",
            "\n",
            "Val Loss: 0.00799\n",
            "***************************************************\n",
            "\n",
            "Epoch: 104\n",
            "\n",
            "Val Loss: 0.00768\n",
            "***************************************************\n",
            "\n",
            "Epoch: 105\n",
            "\n",
            "Val Loss: 0.00820\n",
            "***************************************************\n",
            "\n",
            "Epoch: 106\n",
            "\n",
            "Val Loss: 0.00820\n",
            "***************************************************\n",
            "\n",
            "Epoch: 107\n",
            "\n",
            "Val Loss: 0.00837\n",
            "***************************************************\n",
            "\n",
            "Epoch: 108\n",
            "\n",
            "Val Loss: 0.00803\n",
            "***************************************************\n",
            "\n",
            "Epoch: 109\n",
            "\n",
            "Val Loss: 0.00621\n",
            "***************************************************\n",
            "\n",
            "Epoch: 110\n",
            "\n",
            "Val Loss: 0.00705\n",
            "***************************************************\n",
            "\n",
            "Epoch: 111\n",
            "\n",
            "Val Loss: 0.00835\n",
            "***************************************************\n",
            "\n",
            "Epoch: 112\n",
            "\n",
            "Val Loss: 0.00686\n",
            "***************************************************\n",
            "\n",
            "Epoch: 113\n",
            "\n",
            "Val Loss: 0.00688\n",
            "***************************************************\n",
            "\n",
            "Epoch: 114\n",
            "\n",
            "Val Loss: 0.00807\n",
            "***************************************************\n",
            "\n",
            "Epoch: 115\n",
            "\n",
            "Val Loss: 0.00583\n",
            "***************************************************\n",
            "\n",
            "Epoch: 116\n",
            "\n",
            "Val Loss: 0.00672\n",
            "***************************************************\n",
            "\n",
            "Epoch: 117\n",
            "\n",
            "Val Loss: 0.00636\n",
            "***************************************************\n",
            "\n",
            "Epoch: 118\n",
            "\n",
            "Val Loss: 0.00627\n",
            "***************************************************\n",
            "\n",
            "Epoch: 119\n",
            "\n",
            "Val Loss: 0.00766\n",
            "***************************************************\n",
            "\n",
            "Epoch: 120\n",
            "\n",
            "Val Loss: 0.00650\n",
            "***************************************************\n",
            "\n",
            "Epoch: 121\n",
            "\n",
            "Val Loss: 0.00683\n",
            "***************************************************\n",
            "\n",
            "Epoch: 122\n",
            "\n",
            "Val Loss: 0.00678\n",
            "***************************************************\n",
            "\n",
            "Epoch: 123\n",
            "\n",
            "Val Loss: 0.00658\n",
            "***************************************************\n",
            "\n",
            "Epoch: 124\n",
            "\n",
            "Val Loss: 0.00677\n",
            "***************************************************\n",
            "\n",
            "Epoch: 125\n",
            "\n",
            "Val Loss: 0.00649\n",
            "***************************************************\n",
            "\n",
            "Early stopping triggered\n"
          ]
        }
      ],
      "source": [
        "gru_model = GRUModel(input_size, num_hidden_layers, num_stacked_layers, output_size)\n",
        "gru_model.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(gru_model.parameters(), lr=learning_rate)\n",
        "early_stopping = EarlyStopping(patience=10, mode='min', verbose=False, save_path='/content/checkpoint_gru.pt')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(gru_model)\n",
        "    stop_criteria = validate_one_epoch(gru_model, early_stopping)\n",
        "\n",
        "    if stop_criteria:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ik57HvnA52C"
      },
      "outputs": [],
      "source": [
        "lstm_model = LSTM(input_size, num_hidden_layers, num_stacked_layers, output_size)\n",
        "lstm_model.load_state_dict(torch.load('/content/checkpoint_lstm.pt'))\n",
        "\n",
        "result = predict_train_test(lstm_model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "lstm_metrics = evaluate_forecast(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-X2adOZAltq"
      },
      "outputs": [],
      "source": [
        "gru_model = GRUModel(input_size, num_hidden_layers, num_stacked_layers, output_size)\n",
        "gru_model.load_state_dict(torch.load('/content/checkpoint_gru.pt'))\n",
        "result = predict_train_test(gru_model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "gru_metrics = evaluate_forecast(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerTS(\n",
        "    input_size=input_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    output_size=output_size,\n",
        "    dropout=dropout)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/checkpoint_transformer.pt'))\n",
        "result = predict_train_test(model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "transformer_metrics = evaluate_forecast(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsPk1D-E2lvT",
        "outputId": "e1758466-d580-4c0e-817f-74fd06165b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnpl-CmQHqeK"
      },
      "outputs": [],
      "source": [
        "def get_params_flops(model, input_size):\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    with torch.cuda.device(0):\n",
        "        macs, _ = get_model_complexity_info(model, input_size, as_strings=False, print_per_layer_stat=False)\n",
        "    flops = macs * 2  # MACs to FLOPs\n",
        "    return params, flops\n",
        "\n",
        "def human_readable(num):\n",
        "    for unit in [\"\", \"K\", \"M\", \"B\"]:\n",
        "        if abs(num) < 1000:\n",
        "            return f\"{num:.2f} {unit}\"\n",
        "        num /= 1000\n",
        "    return f\"{num:.2f} T\"  # trillion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36r5KiGNHw3F"
      },
      "outputs": [],
      "source": [
        "model_info = {}\n",
        "for name, model in {\n",
        "    \"LSTM\": lstm_model,\n",
        "    \"GRU\": gru_model,\n",
        "    \"Transformer\": model\n",
        "}.items():\n",
        "    params, flops = get_params_flops(model, (30, 1))  # (seq_len, input_size)\n",
        "    model_info[name] = {\"Params\": human_readable(params), \"FLOPs\": human_readable(flops)}\n",
        "\n",
        "\n",
        "df_info = pd.DataFrame(model_info).T\n",
        "df_info = df_info.reset_index().rename(columns={'index':'Model'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "GRas0whxAm0f",
        "outputId": "42b60aed-f9fc-4041-eb1a-a4bee5de9a58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           MAE       RMSE      MAPE     sMAPE        R2  \\\n",
              "Model       Dataset                                                       \n",
              "LSTM        train    27.989830  38.989189  0.060203  0.060190  0.990512   \n",
              "            test     45.204918  59.094742  0.094563  0.094631  0.904518   \n",
              "GRU         train    26.490988  38.961105  0.056988  0.056981  0.990523   \n",
              "            test     66.061127  83.549095  0.138142  0.138289  0.809143   \n",
              "Transformer train    25.080482  38.251038  0.053899  0.053898  0.990865   \n",
              "            test     41.446842  51.369881  0.086780  0.086812  0.927849   \n",
              "\n",
              "                         MASE    Params   FLOPs  \n",
              "Model       Dataset                              \n",
              "LSTM        train    1.227784   117.00   9.13 K  \n",
              "            test     1.982931   117.00   9.13 K  \n",
              "GRU         train    1.161850    89.00   6.73 K  \n",
              "            test     2.897329    89.00   6.73 K  \n",
              "Transformer train    1.099853  100.29 K  5.51 M  \n",
              "            test     1.817566  100.29 K  5.51 M  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdcd1f68-9ffe-4d87-b331-3cc4e9503e9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>sMAPE</th>\n",
              "      <th>R2</th>\n",
              "      <th>MASE</th>\n",
              "      <th>Params</th>\n",
              "      <th>FLOPs</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th>Dataset</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">LSTM</th>\n",
              "      <th>train</th>\n",
              "      <td>27.989830</td>\n",
              "      <td>38.989189</td>\n",
              "      <td>0.060203</td>\n",
              "      <td>0.060190</td>\n",
              "      <td>0.990512</td>\n",
              "      <td>1.227784</td>\n",
              "      <td>117.00</td>\n",
              "      <td>9.13 K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>45.204918</td>\n",
              "      <td>59.094742</td>\n",
              "      <td>0.094563</td>\n",
              "      <td>0.094631</td>\n",
              "      <td>0.904518</td>\n",
              "      <td>1.982931</td>\n",
              "      <td>117.00</td>\n",
              "      <td>9.13 K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">GRU</th>\n",
              "      <th>train</th>\n",
              "      <td>26.490988</td>\n",
              "      <td>38.961105</td>\n",
              "      <td>0.056988</td>\n",
              "      <td>0.056981</td>\n",
              "      <td>0.990523</td>\n",
              "      <td>1.161850</td>\n",
              "      <td>89.00</td>\n",
              "      <td>6.73 K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>66.061127</td>\n",
              "      <td>83.549095</td>\n",
              "      <td>0.138142</td>\n",
              "      <td>0.138289</td>\n",
              "      <td>0.809143</td>\n",
              "      <td>2.897329</td>\n",
              "      <td>89.00</td>\n",
              "      <td>6.73 K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Transformer</th>\n",
              "      <th>train</th>\n",
              "      <td>25.080482</td>\n",
              "      <td>38.251038</td>\n",
              "      <td>0.053899</td>\n",
              "      <td>0.053898</td>\n",
              "      <td>0.990865</td>\n",
              "      <td>1.099853</td>\n",
              "      <td>100.29 K</td>\n",
              "      <td>5.51 M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>41.446842</td>\n",
              "      <td>51.369881</td>\n",
              "      <td>0.086780</td>\n",
              "      <td>0.086812</td>\n",
              "      <td>0.927849</td>\n",
              "      <td>1.817566</td>\n",
              "      <td>100.29 K</td>\n",
              "      <td>5.51 M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdcd1f68-9ffe-4d87-b331-3cc4e9503e9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdcd1f68-9ffe-4d87-b331-3cc4e9503e9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdcd1f68-9ffe-4d87-b331-3cc4e9503e9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5c1c6f13-c46b-4297-bcc4-c10f012726b3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c1c6f13-c46b-4297-bcc4-c10f012726b3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5c1c6f13-c46b-4297-bcc4-c10f012726b3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"comparison\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          27.989830017089844,\n          45.204917907714844,\n          41.446842193603516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          38.98918914794922,\n          59.09474182128906,\n          51.36988067626953\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAPE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.06020345538854599,\n          0.09456338733434677,\n          0.08678030222654343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sMAPE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.06019008159637451,\n          0.09463087469339371,\n          0.08681194484233856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9905117154121399,\n          0.9045180082321167,\n          0.9278492331504822\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MASE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.2277843952178955,\n          1.9829306602478027,\n          1.8175660371780396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Params\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"117.00 \",\n          \"89.00 \",\n          \"100.29 K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLOPs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"9.13 K\",\n          \"6.73 K\",\n          \"5.51 M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "results = {\n",
        "    \"LSTM\": lstm_metrics,\n",
        "    \"GRU\": gru_metrics,\n",
        "    \"Transformer\": transformer_metrics\n",
        "}\n",
        "\n",
        "\n",
        "comparison = pd.concat({model: pd.DataFrame(metrics).T for model, metrics in results.items()})\n",
        "\n",
        "comparison = comparison.reset_index().rename(columns={'level_0':'Model', 'level_1':'Dataset'})\n",
        "\n",
        "comparison = comparison.merge(df_info, on=\"Model\")\n",
        "\n",
        "comparison.set_index(['Model',\t'Dataset'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = BaselineModel(sample_mean=6)\n",
        "result = predict_train_test(baseline_model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "\n",
        "plot_predictions_plotly(result, horizon_step=0, title=\"Gold Price Forecast\")\n",
        "\n",
        "\n",
        "transformer_metrics = evaluate_forecast(result)\n",
        "transformer_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "WBOdtFHOIK1Y",
        "outputId": "067af123-63f0-4a31-839f-f968876b59e8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"8690ad9b-e983-4a89-aebd-ce9aac52fc40\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8690ad9b-e983-4a89-aebd-ce9aac52fc40\")) {                    Plotly.newPlot(                        \"8690ad9b-e983-4a89-aebd-ce9aac52fc40\",                        [{\"line\":{\"color\":\"blue\"},\"mode\":\"lines\",\"name\":\"Train Actual\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657],\"y\":[45983.35,45960.906,46025.312,45969.734,45889.08,45871.39,45900.105,45972.246,45983.152,45972.56,45957.664,45929.945,45936.02,45935.926,45945.76,45934.438,45938.344,45932.14,45919.176,45908.58,45922.34,45930.887,45949.496,46005.043,45957.96,45826.508,45883.06,45894.652,45965.31,46005.805,46003.848,45965.418,45904.617,45950.227,45979.52,45980.89,45979.1,45978.348,45980.23,45980.414,45977.938,45981.23,45980.953,45969.523,45985.93,45988.812,45927.996,45795.824,45792.66,45870.082,45841.47,45816.918,45858.984,45880.09,45880.305,45878.043,45993.645,46076.688,46066.676,46103.11,46100.72,46100.645,46100.07,46098.434,46100.625,46100.76,46100.125,46099.547,46154.54,46194.273,46215.11,46241.492,46336.16,46375.387,46323.914,46359.24,46413.543,46437.395,46308.36,46302.562,46308.61,46248.0,46279.92,46298.57,46330.22,46329.746,46329.95,46329.3,46331.617,46330.234,46329.99,46328.92,46329.668,46327.016,46425.82,46460.965,46313.777,46260.535,46287.188,46276.74,46273.844,46213.207,46283.703,46352.83,46372.918,46362.996,46438.43,46367.156,46358.742,46359.34,46358.88,46359.152,46360.07,46360.117,46359.19,46359.76,46359.094,46236.76,46177.477,46148.344,46116.473,45975.062,45895.617,45875.348,45867.793,45832.527,45939.81,45942.145,45992.523,46058.67,46111.863,46085.11,46049.895,46051.867,46049.734,46049.516,46049.52,46049.996,46050.84,46050.754,45943.312,45982.805,46023.86,46128.926,46214.88,46277.664,46222.312,46164.562,46186.312,46162.773,46241.61,46229.13,46224.543,46226.516,46228.902,46202.42,46198.223,46212.906,46216.33,46219.87,46226.152,46224.06,46218.426,46255.27,46270.418,46352.707,46470.473,46422.754,46426.02,46433.438,46446.27,46443.867,46377.805,46357.93,46385.36,46427.645,46470.44,46458.48,46458.695,46460.367,46466.902,46464.04,46461.957,46462.574,46465.24,46461.37,46459.504,46459.78,46464.418,46464.305,46471.39,46489.535,46481.51,46433.973,46440.055,46417.04,46372.664,46322.957,46293.977,46284.63,46232.445,46233.367,46237.074,46288.652,46286.113,46280.527,46275.035,46259.895,46241.176,46234.906,46230.65,46224.516,46229.44,46251.906,46352.453,46286.12,46255.312,46343.043,46389.453,46369.152,46380.164,46307.73,46315.715,46335.855,46350.17,46330.98,46329.863,46338.04,46339.938,46341.273,46343.965,46340.75,46339.746,46339.42,46338.695,46341.88,46341.52,46342.914,46507.707,46606.2,46671.227,46690.41,46664.832,46720.574,46746.45,46777.855,46768.97,46825.426,46868.18,46837.816,46805.723,46832.305,46839.773,46840.957,46833.152,46829.867,46835.887,46830.664,46843.156,46847.367,46849.883,46838.574,46828.395,46812.055,46726.26,46717.895,46684.902,46679.906,46629.344,46648.66,46640.848,46644.703,46620.25,46618.598,46615.68,46618.957,46630.57,46625.54,46625.74,46628.508,46632.51,46630.01,46636.65,46625.0,46623.137,46615.254,46643.508,46652.426,46636.5,46590.82,46577.246,46507.22,46522.09,46493.35,46495.277,46528.14,46517.52,46509.715,46511.453,46509.062,46510.043,46509.66,46511.793,46517.934,46517.086,46514.8,46518.305,46512.793,46509.047,46501.414,46497.176,46416.273,46377.223,46389.46,46408.61,46401.074,46376.805,46383.023,46387.66,46401.242,46422.387,46415.473,46416.184,46400.44,46400.402,46400.105,46400.625,46404.16,46400.707,46398.992,46400.45,46397.312,46400.836,46413.324,46464.83,46504.43,46537.25,46507.547,46520.805,46533.332,46528.305,46492.938,46470.86,46463.93,46458.78,46462.95,46457.78,46460.355,46462.566,46463.785,46459.41,46460.07,46463.406,46463.41,46459.656,46460.86,46462.31,46461.953,46462.55,46461.89,46466.504,46458.344,46451.785,46429.63,46409.15,46369.277,46379.098,46308.223,46303.867,46298.75,46293.75,46368.336,46402.77,46390.023,46379.977,46381.023,46379.105,46368.01,46367.855,46360.18,46334.33,46327.934,46271.207,46409.18,46290.87,46246.59,46227.242,46175.08,46147.453,46173.902,46111.113,46096.355,46131.55,46113.68,46106.457,46134.496,46188.895,46183.285,46166.02,46160.13,46160.703,46159.35,46160.57,46153.625,46143.176,46199.617,46249.406,46196.926,46148.344,46159.973,46162.43,46197.293,46181.766,46168.215,46181.684,46207.93,46210.3,46226.125,46222.7,46217.15,46210.688,46210.273,46208.79,46209.723,46208.344,46210.207,46209.2,46209.86,46203.11,46199.082,46207.855,46163.387,46264.5,46396.938,46398.566,46418.535,46421.965,46379.285,46364.45,46374.867,46354.688,46328.09,46308.5,46355.44,46354.094,46357.137,46348.07,46347.227,46344.29,46343.402,46339.254,46340.688,46322.246,46329.836,46391.152,46373.996,46324.188,46461.43,46495.496,46505.09,46506.145,46449.316,46506.312,46587.797,46589.56,46558.332,46559.402,46573.64,46579.543,46575.285,46572.7,46572.33,46570.996,46568.88,46569.34,46577.434,46621.133,46660.695,46669.504,46700.117,46710.645,46720.74,46718.387,46652.15,46613.977,46622.695,46639.08,46674.934,46633.883,46610.918,46615.695,46638.34,46645.832,46636.035,46639.844,46640.215,46640.715,46639.71,46633.043,46629.73,46632.055,46622.68,46618.117,46530.17,46542.234,46562.61,46592.145,46600.457,46622.656,46655.918,46675.586,46690.65,46705.48,46682.465,46678.812,46670.363,46667.613,46670.812,46681.465,46682.723,46685.21,46698.08,46690.977,46693.344,46697.15,46703.848,46734.066,46782.215,46791.926,46738.45,46767.87,46784.49,46830.727,46828.797,46937.81,47000.918,46985.26,47111.293,47146.38,47184.445,47201.812,47169.81,47162.14,47148.16,47139.004,47139.973,47149.406,47141.91,47156.22,47174.11,47151.875,47142.71,47273.613,47300.945,47344.836,47307.168,47249.047,47251.09,47198.254,47151.062,47167.973,47142.324,47130.402,47133.617,47131.082,47129.598,47130.39,47129.742,47130.016,47128.68,47129.934,47121.63,47115.09,47115.74,47136.55,47027.598,46990.176,46938.414,46955.836,46984.707,46965.76,46996.84,47002.027,47018.684,47009.617,47008.22,47006.156,47009.234,47010.01,47021.44,47029.43,47029.344,47030.508,47034.36,47036.91,47038.066,47038.543,47023.992,46931.656,46986.05,47086.203,47107.797,47101.37,47082.01,47081.645,47088.055,47103.168,47183.285,47177.01,47178.18,47172.285,47187.855,47190.168,47189.496,47184.887,47187.797,47184.65,47182.582,47180.492,47181.066,47183.242,47187.113,47216.438,47268.652,47249.234,47317.52,47340.387,47299.406,47438.766,47539.71,47471.613,47435.133,47395.22,47411.773,47402.39,47416.418,47420.332,47420.76,47420.754,47420.17,47419.66,47411.855,47410.582,47409.727,47401.797,47439.906,47493.703,47469.965,47396.863,47423.375,47416.145,47411.18,47399.14,47430.203,47414.65,47410.914,47416.66,47453.82],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\",\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Train Pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657],\"y\":[45921.777,45939.715,45956.156,45982.64,45990.418,45979.277,45950.24,45936.645,45937.805,45930.82,45931.55,45942.227,45951.824,45958.32,45951.76,45946.508,45939.965,45936.51,45937.043,45934.617,45929.887,45925.96,45925.01,45927.29,45939.188,45945.88,45932.574,45924.85,45919.957,45921.785,45921.742,45929.28,45952.55,45955.867,45965.312,45967.695,45963.53,45959.45,45962.227,45975.113,45980.344,45979.785,45979.438,45979.645,45977.48,45979.72,45980.85,45972.785,45942.367,45910.844,45894.52,45870.863,45841.395,45830.027,45843.676,45858.23,45859.37,45884.508,45927.28,45961.984,45999.77,46036.234,46073.625,46091.45,46095.02,46100.79,46100.156,46099.895,46100.668,46109.555,46125.63,46143.36,46167.23,46206.484,46252.184,46280.55,46307.94,46341.06,46374.242,46370.02,46357.62,46355.145,46336.63,46314.29,46291.184,46295.098,46299.4,46302.465,46315.98,46325.01,46330.098,46330.18,46330.13,46329.92,46329.39,46345.664,46367.14,46364.633,46353.473,46345.93,46338.293,46312.457,46271.66,46266.496,46281.67,46295.58,46310.086,46337.164,46362.89,46376.242,46377.023,46374.54,46373.934,46360.707,46359.65,46359.855,46359.55,46359.65,46339.38,46308.9,46274.082,46233.11,46169.312,46091.652,46031.668,45979.77,45927.08,45897.477,45891.547,45908.145,45938.36,45979.145,46021.57,46040.164,46058.16,46067.41,46066.098,46055.918,46050.312,46049.824,46049.633,46031.926,46021.812,46017.18,46030.055,46057.63,46096.12,46142.305,46172.227,46199.766,46205.24,46209.402,46200.656,46201.883,46212.195,46218.785,46226.1,46218.59,46215.535,46214.312,46212.82,46212.27,46216.66,46220.074,46227.215,46235.87,46258.457,46299.37,46332.44,46366.652,46396.37,46425.516,46440.418,46425.184,46414.387,46407.715,46406.87,46410.824,46413.4,46426.445,46443.49,46456.633,46463.168,46461.23,46462.15,46463.61,46463.59,46462.23,46461.758,46462.32,46462.355,46463.543,46468.285,46472.21,46467.91,46463.664,46455.74,46439.09,46411.26,46380.23,46355.1,46320.457,46290.016,46267.6,46261.918,46260.67,46259.66,46267.07,46271.945,46272.24,46263.04,46254.06,46244.402,46236.35,46235.293,46253.973,46262.32,46266.8,46286.215,46313.426,46332.582,46337.277,46340.844,46350.457,46349.836,46343.395,46336.805,46328.832,46333.62,46338.133,46338.477,46337.5,46339.188,46341.055,46340.836,46341.055,46340.754,46340.832,46341.01,46369.113,46413.28,46468.88,46527.08,46580.508,46643.348,46683.426,46711.914,46728.23,46750.72,46784.637,46804.254,46814.008,46823.02,46834.85,46837.414,46831.59,46830.336,46835.35,46835.04,46835.59,46836.605,46839.465,46840.953,46839.676,46836.594,46817.082,46795.605,46768.016,46741.582,46708.22,46680.926,46666.69,46654.48,46643.71,46633.56,46631.324,46626.387,46624.863,46621.645,46622.617,46624.367,46627.04,46628.934,46630.07,46629.656,46629.293,46626.97,46628.758,46632.43,46632.633,46626.62,46618.95,46601.008,46580.92,46554.41,46531.066,46520.11,46510.29,46510.824,46509.24,46511.605,46514.34,46511.566,46510.426,46511.773,46512.81,46513.72,46515.22,46515.99,46515.55,46512.484,46509.22,46492.527,46468.82,46448.543,46431.54,46415.08,46394.71,46389.24,46391.207,46393.277,46395.293,46397.58,46404.023,46407.17,46409.566,46408.992,46405.617,46403.938,46401.312,46400.973,46400.82,46400.344,46400.54,46401.773,46412.84,46430.336,46452.824,46471.535,46491.49,46511.54,46521.848,46519.812,46508.82,46501.54,46491.227,46479.566,46468.176,46462.188,46461.27,46461.273,46461.53,46460.62,46461.473,46461.906,46461.555,46461.312,46461.406,46461.844,46461.516,46461.47,46462.82,46462.164,46460.273,46455.17,46446.42,46430.484,46416.254,46391.15,46366.625,46344.504,46325.375,46325.375,46329.258,46343.145,46355.777,46369.168,46383.64,46383.508,46377.504,46372.637,46364.824,46356.207,46338.344,46345.32,46332.082,46313.508,46295.395,46270.465,46249.25,46210.086,46180.145,46155.11,46138.723,46128.777,46121.914,46115.227,46128.016,46142.56,46148.223,46156.684,46165.492,46169.688,46164.613,46159.957,46156.13,46162.89,46177.758,46183.902,46182.027,46183.01,46185.926,46185.21,46174.15,46169.83,46175.324,46182.887,46191.207,46195.66,46202.52,46211.145,46215.535,46215.918,46216.086,46213.594,46210.8,46209.664,46209.74,46209.19,46209.375,46206.934,46206.918,46198.445,46207.79,46239.02,46271.51,46307.97,46343.805,46379.773,46396.312,46393.04,46385.51,46370.266,46351.543,46347.49,46345.977,46342.83,46341.27,46344.742,46351.152,46348.79,46346.453,46344.15,46339.57,46336.703,46344.043,46349.324,46346.81,46367.137,46395.965,46425.14,46444.332,46456.887,46487.02,46507.992,46523.72,46532.984,46541.875,46562.56,46574.953,46572.938,46570.008,46572.25,46574.254,46573.44,46571.566,46571.79,46579.895,46594.81,46611.2,46632.875,46656.36,46680.418,46696.582,46695.11,46685.87,46673.22,46661.234,46653.418,46639.516,46632.516,46632.918,46635.43,46636.523,46630.156,46631.05,46635.883,46640.066,46640.33,46638.13,46637.24,46635.863,46633.047,46629.332,46610.94,46595.95,46584.844,46578.16,46574.45,46575.176,46596.062,46618.37,46639.53,46658.23,46672.254,46681.527,46683.812,46682.46,46679.37,46675.02,46675.17,46676.395,46681.05,46685.082,46688.65,46691.395,46694.754,46703.016,46717.074,46733.645,46741.215,46753.17,46766.56,46782.684,46790.348,46814.72,46858.42,46894.63,46949.105,47001.816,47060.87,47104.96,47133.418,47162.746,47168.875,47167.54,47160.28,47151.465,47146.668,47145.79,47150.066,47152.113,47152.633,47173.402,47200.01,47231.438,47253.75,47269.52,47287.785,47275.27,47250.348,47220.82,47193.36,47173.75,47153.824,47142.824,47139.28,47132.938,47130.92,47130.883,47130.08,47129.74,47128.42,47125.97,47123.582,47124.582,47107.82,47084.516,47054.02,47027.453,47005.53,46977.09,46971.973,46974.0,46987.375,46996.375,47000.336,47006.992,47009.035,47010.41,47010.77,47014.113,47017.625,47021.723,47025.89,47030.367,47033.11,47034.746,47033.703,47017.254,47009.188,47017.426,47028.953,47039.535,47049.074,47074.133,47091.082,47094.008,47106.562,47119.312,47135.105,47150.31,47167.043,47181.414,47182.617,47183.96,47185.49,47187.547,47186.324,47184.81,47183.5,47183.16,47183.15,47188.387,47202.81,47214.188,47236.848,47263.242,47281.65,47318.64,47364.066,47400.96,47420.785,47429.72,47448.914,47442.508,47421.758,47413.3,47411.074,47414.785,47416.56,47419.234,47418.902,47417.113,47415.273,47412.14,47415.74,47427.77,47437.547,47435.16,47437.395,47439.96,47434.996,47419.12,47412.676,47415.367,47413.28,47413.766],\"type\":\"scatter\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"Test Actual\",\"x\":[658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731],\"y\":[47354.723,47386.867,47480.477,47473.496,47487.812,47481.54,47479.62,47470.945,47472.492,47478.9,47458.195,47448.29,47460.25,47502.414,47531.24,47498.434,47501.688,47516.1,47485.664,47526.723,47534.07,47558.37,47580.25,47563.18,47553.977,47579.523,47578.06,47567.715,47581.76,47578.43,47569.055,47570.44,47555.64,47533.176,47540.406,47546.89,47586.316,47688.715,47680.273,47713.484,47752.676,47771.42,47776.61,47787.48,47793.324,47894.84,47900.336,47876.62,47871.887,47895.88,47923.523,47921.543,47915.22,47883.438,47889.65,47888.965,47884.215,47877.965,47851.34,47849.41,47919.895,48024.168,48001.297,47956.777,47951.668,47942.934,47936.01,47891.285,47869.402,47898.98,47915.797,47921.13,47899.66,47902.406],\"type\":\"scatter\"},{\"line\":{\"color\":\"orange\",\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Test Pred\",\"x\":[658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731],\"y\":[47420.9,47413.48,47406.254,47417.316,47427.71,47439.484,47444.152,47464.97,47478.984,47477.652,47478.55,47473.613,47468.07,47464.848,47470.09,47479.88,47483.137,47490.383,47501.688,47505.926,47509.977,47510.45,47520.438,47533.53,47541.375,47552.76,47561.56,47568.89,47570.453,47570.703,47573.246,47575.758,47574.242,47570.508,47564.75,47557.86,47552.6,47555.48,47575.19,47595.965,47626.01,47661.39,47698.816,47730.53,47746.992,47765.832,47796.06,47820.668,47838.203,47854.08,47872.15,47893.844,47898.3,47900.777,47901.914,47904.875,47903.723,47897.17,47889.91,47879.266,47873.59,47878.633,47901.164,47920.68,47933.812,47950.535,47966.12,47968.805,47946.66,47924.68,47915.047,47909.066,47905.438,47899.375],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"color\":\"black\",\"dash\":\"dot\",\"width\":2},\"type\":\"line\",\"x0\":657.5,\"x1\":657.5,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}],\"legend\":{\"x\":0,\"y\":1},\"title\":{\"text\":\"Gold Price Forecast\"},\"xaxis\":{\"title\":{\"text\":\"Sample Index (time ordered)\"}},\"yaxis\":{\"title\":{\"text\":\"Price\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8690ad9b-e983-4a89-aebd-ce9aac52fc40');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'MAE': np.float32(42.845684),\n",
              "  'RMSE': np.float32(65.09022),\n",
              "  'MAPE': np.float32(0.0921522),\n",
              "  'sMAPE': np.float32(0.09217652),\n",
              "  'R2': np.float32(0.9735557),\n",
              "  'MASE': np.float32(1.87957)},\n",
              " 'test': {'MAE': np.float32(40.150284),\n",
              "  'RMSE': np.float32(53.662918),\n",
              "  'MAPE': np.float32(0.08411537),\n",
              "  'sMAPE': np.float32(0.08416282),\n",
              "  'R2': np.float32(0.9212642),\n",
              "  'MASE': np.float32(1.7613273)}}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "6DKAPUcsyJD7",
        "outputId": "99ccfe75-536d-4727-a7f4-1f15e780818c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4f2dea95-f10d-4801-b46a-d1cd50920153\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4f2dea95-f10d-4801-b46a-d1cd50920153\")) {                    Plotly.newPlot(                        \"4f2dea95-f10d-4801-b46a-d1cd50920153\",                        [{\"line\":{\"color\":\"blue\"},\"mode\":\"lines\",\"name\":\"Train Actual\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657],\"y\":[45984.7,45960.418,46025.16,45970.53,45889.5,45871.535,45901.934,45972.777,45983.24,45971.086,45955.684,45929.152,45936.49,45934.76,45946.96,45935.03,45939.8,45930.812,45919.777,45908.8,45921.008,45929.89,45951.367,46005.918,45957.277,45827.523,45883.08,45894.59,45964.24,46004.156,46003.49,45965.074,45903.426,45951.33,45980.3,45979.82,45979.797,45978.902,45978.76,45979.42,45977.55,45979.52,45978.23,45970.82,45986.85,45989.863,45929.59,45798.12,45795.36,45869.4,45841.812,45816.668,45859.414,45880.613,45882.69,45876.973,45993.332,46075.613,46068.57,46102.62,46099.465,46099.55,46099.49,46099.25,46100.656,46101.605,46101.133,46100.3,46154.29,46194.414,46214.668,46240.64,46335.34,46374.434,46324.188,46359.344,46413.1,46437.652,46308.688,46302.82,46308.957,46247.41,46279.047,46299.883,46330.312,46330.07,46329.688,46329.76,46330.598,46330.605,46329.598,46329.312,46329.523,46326.867,46425.934,46460.82,46315.01,46261.44,46288.117,46277.52,46273.902,46213.44,46283.34,46352.15,46373.242,46362.086,46439.11,46366.95,46360.42,46359.99,46359.734,46359.668,46360.688,46360.92,46359.484,46359.785,46359.96,46235.492,46178.46,46149.793,46115.555,45975.59,45893.598,45874.56,45865.727,45832.832,45938.39,45942.055,45994.145,46058.0,46110.99,46082.703,46050.406,46050.594,46050.13,46049.375,46049.234,46050.383,46050.492,46049.96,45943.03,45983.832,46025.047,46129.676,46214.684,46278.15,46222.562,46165.25,46185.727,46163.957,46240.54,46228.863,46224.516,46226.883,46227.965,46203.27,46197.59,46212.336,46216.508,46219.508,46226.984,46225.63,46219.45,46255.145,46271.688,46353.867,46470.227,46423.496,46425.414,46434.156,46445.59,46445.08,46378.13,46357.652,46385.086,46428.523,46470.68,46459.586,46458.63,46460.273,46465.984,46463.945,46462.348,46462.418,46465.72,46460.176,46459.72,46459.734,46463.887,46465.117,46471.113,46489.14,46482.15,46434.637,46439.777,46417.344,46372.47,46323.395,46294.027,46284.812,46231.855,46234.168,46237.88,46289.13,46287.605,46280.43,46276.785,46260.85,46241.28,46235.145,46231.676,46224.574,46227.996,46251.008,46352.92,46287.04,46253.984,46342.984,46390.09,46370.06,46379.99,46308.176,46316.316,46336.62,46350.125,46331.816,46330.227,46338.758,46340.22,46341.824,46343.965,46340.527,46339.39,46339.938,46339.04,46341.27,46341.938,46342.016,46507.71,46605.938,46671.39,46690.387,46664.688,46720.29,46746.695,46778.137,46768.953,46825.566,46868.184,46837.695,46805.785,46832.35,46839.824,46841.043,46833.223,46829.77,46835.86,46830.676,46843.145,46847.266,46849.758,46838.64,46828.53,46812.05,46726.02,46717.707,46684.773,46679.78,46628.59,46648.4,46640.676,46644.875,46619.645,46618.426,46615.324,46619.473,46630.574,46624.93,46625.824,46629.297,46632.855,46629.848,46636.78,46624.676,46622.938,46615.26,46643.223,46651.812,46636.164,46591.223,46577.883,46506.926,46521.152,46492.445,46495.78,46526.887,46517.195,46509.777,46511.76,46509.133,46510.19,46509.805,46511.73,46519.01,46517.31,46515.152,46518.883,46512.64,46509.16,46501.13,46496.957,46415.723,46377.367,46389.406,46408.133,46402.227,46377.027,46382.41,46387.957,46400.754,46421.03,46415.676,46416.203,46399.875,46400.21,46399.21,46400.992,46405.13,46400.41,46400.5,46400.254,46397.22,46401.168,46412.844,46465.797,46504.332,46536.793,46507.934,46521.184,46533.234,46529.125,46491.965,46471.254,46464.492,46457.844,46463.32,46458.52,46459.945,46462.387,46463.49,46459.38,46460.09,46463.72,46462.99,46459.79,46460.797,46462.32,46461.07,46461.43,46463.516,46466.363,46457.523,46451.95,46429.043,46409.562,46369.258,46377.848,46308.01,46304.023,46298.91,46293.547,46369.016,46402.72,46390.36,46379.906,46380.727,46378.27,46368.52,46367.117,46359.867,46332.02,46328.047,46271.395,46408.53,46291.484,46246.746,46226.996,46176.38,46146.066,46173.883,46110.64,46095.68,46130.965,46115.11,46106.46,46133.46,46188.566,46183.113,46167.11,46160.31,46159.71,46159.695,46161.2,46153.227,46142.605,46199.227,46248.562,46196.87,46149.47,46159.92,46163.19,46196.58,46183.137,46169.02,46181.008,46209.824,46208.95,46225.562,46222.85,46217.844,46208.77,46211.38,46210.35,46209.746,46209.14,46211.49,46210.258,46209.145,46204.188,46198.98,46207.934,46163.434,46263.61,46396.44,46398.906,46418.508,46421.44,46380.207,46364.387,46375.6,46355.043,46327.344,46307.383,46355.496,46353.594,46356.457,46346.617,46348.047,46344.28,46343.105,46339.73,46341.625,46322.035,46329.664,46391.34,46374.09,46324.56,46462.297,46495.047,46504.047,46506.35,46449.957,46506.426,46587.953,46589.473,46559.027,46559.207,46574.01,46579.652,46575.492,46573.18,46572.438,46571.586,46568.78,46569.63,46577.133,46620.723,46661.113,46669.504,46699.758,46710.617,46720.617,46718.21,46651.973,46614.28,46622.08,46638.89,46674.93,46634.13,46610.613,46615.617,46638.527,46645.633,46636.156,46639.555,46639.72,46640.664,46639.707,46633.08,46629.883,46632.56,46623.355,46617.81,46530.312,46542.773,46562.164,46592.703,46600.832,46621.9,46656.31,46675.44,46691.176,46705.164,46682.562,46678.79,46670.176,46667.88,46670.37,46681.344,46682.96,46685.03,46698.09,46691.117,46693.465,46697.02,46703.7,46733.996,46782.375,46791.79,46738.336,46768.164,46784.566,46830.73,46828.81,46937.77,47000.953,46985.13,47111.566,47146.9,47183.7,47201.758,47170.105,47162.27,47147.418,47139.734,47139.836,47149.61,47141.72,47155.72,47174.19,47152.344,47142.73,47272.832,47301.785,47345.188,47306.98,47249.375,47250.84,47198.117,47151.418,47167.938,47142.36,47130.03,47133.703,47130.945,47129.773,47130.625,47130.062,47129.477,47128.793,47129.883,47121.184,47114.82,47115.934,47136.574,47027.566,46990.15,46938.426,46955.934,46984.797,46965.78,46996.777,47002.17,47018.68,47009.605,47008.125,47006.473,47009.37,47010.055,47021.387,47029.586,47029.633,47030.656,47034.344,47037.01,47038.137,47038.785,47023.938,46931.695,46986.05,47085.85,47108.164,47101.004,47081.934,47081.54,47088.113,47103.195,47183.25,47176.84,47178.53,47172.14,47188.168,47189.555,47189.457,47185.17,47188.434,47183.883,47182.52,47180.645,47181.04,47182.707,47187.113,47216.625,47268.883,47249.45,47316.965,47340.7,47299.395,47438.57,47539.56,47471.383,47434.78,47395.617,47411.113,47402.2,47415.66,47419.598,47420.95,47419.434,47419.582,47419.746,47411.918,47410.6,47410.0,47400.508,47440.3,47494.887,47470.48,47396.777,47422.56,47416.07,47410.906,47399.29,47430.355,47414.305,47411.17,47416.83,47453.92],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\",\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Train Pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657],\"y\":[46044.043,45985.984,45964.7,46023.586,45973.305,45900.223,45885.836,45909.73,45973.637,45985.695,45973.207,45960.758,45939.117,45941.305,45940.516,45951.152,45940.5,45943.62,45938.07,45926.473,45917.37,45929.316,45937.074,45956.375,46004.992,45962.332,45849.996,45895.32,45906.55,45966.88,46004.395,46003.785,45968.355,45914.793,45953.125,45980.797,45981.793,45981.188,45980.12,45981.594,45982.43,45978.727,45980.16,45980.445,45971.91,45984.95,45989.71,45935.8,45828.117,45825.28,45885.93,45864.492,45843.44,45875.543,45894.695,45897.312,45893.125,45993.37,46074.258,46065.09,46099.71,46095.68,46093.555,46094.74,46093.195,46093.48,46094.047,46093.754,46094.137,46149.137,46190.957,46213.117,46239.668,46336.004,46377.33,46322.86,46358.176,46416.676,46442.973,46305.996,46299.434,46304.812,46244.438,46273.7,46294.824,46326.91,46327.547,46327.92,46326.645,46328.695,46327.484,46327.812,46326.51,46326.605,46324.67,46429.46,46467.258,46311.15,46256.918,46281.87,46272.152,46269.043,46207.63,46280.156,46351.19,46372.273,46361.688,46444.277,46366.57,46358.79,46358.566,46356.707,46356.492,46359.207,46358.344,46357.754,46358.285,46357.16,46230.3,46168.383,46140.137,46105.453,45971.492,45901.08,45885.363,45879.09,45853.227,45941.98,45946.438,45993.016,46055.65,46107.62,46079.742,46046.492,46046.547,46045.152,46045.168,46045.168,46045.21,46045.566,46045.746,45946.867,45983.574,46019.727,46124.73,46216.008,46278.402,46221.09,46159.145,46181.992,46158.17,46240.25,46227.34,46223.008,46223.504,46226.223,46199.117,46193.016,46208.45,46213.93,46216.18,46223.58,46222.54,46216.96,46252.79,46268.234,46352.863,46478.04,46427.438,46429.207,46438.117,46452.652,46449.723,46377.066,46354.633,46384.16,46430.094,46475.94,46464.58,46464.152,46464.992,46472.09,46468.69,46466.57,46467.633,46470.09,46465.453,46464.496,46464.93,46469.383,46470.09,46476.973,46494.05,46485.777,46437.758,46443.645,46417.434,46369.91,46318.53,46286.9,46278.805,46226.83,46227.66,46231.863,46285.684,46283.508,46276.33,46272.84,46256.45,46237.176,46231.895,46227.242,46220.082,46226.445,46248.336,46353.445,46283.14,46251.242,46341.875,46391.44,46369.52,46380.855,46304.67,46311.88,46333.4,46348.418,46327.902,46326.785,46335.227,46337.027,46338.535,46341.496,46338.086,46337.363,46336.785,46336.496,46339.11,46340.273,46339.945,46513.38,46612.652,46677.324,46695.445,46670.28,46724.258,46749.668,46781.48,46771.355,46833.14,46877.383,46845.1,46810.805,46839.008,46846.82,46848.016,46840.04,46836.68,46842.734,46837.574,46850.13,46854.355,46856.945,46845.48,46835.16,46817.87,46725.797,46717.97,46687.23,46682.207,46630.79,46649.902,46642.523,46646.902,46622.957,46621.633,46618.71,46622.35,46633.723,46628.324,46629.215,46632.344,46635.64,46632.996,46640.562,46628.4,46626.156,46618.742,46646.516,46655.598,46640.0,46594.13,46580.77,46509.93,46524.87,46496.223,46498.945,46531.246,46520.13,46514.38,46515.496,46513.008,46514.098,46513.5,46515.508,46522.93,46521.348,46519.062,46522.637,46516.566,46512.906,46505.95,46501.367,46415.46,46374.55,46387.453,46407.46,46401.527,46373.855,46381.15,46386.926,46401.703,46424.26,46417.645,46418.62,46401.414,46401.336,46399.906,46401.625,46406.203,46400.484,46399.51,46400.74,46397.625,46402.27,46415.293,46470.926,46509.37,46542.125,46512.605,46525.38,46538.625,46533.06,46496.426,46475.05,46468.91,46462.613,46468.395,46463.19,46464.676,46466.83,46468.3,46464.574,46465.19,46468.94,46468.168,46465.816,46466.582,46468.156,46466.18,46466.31,46468.055,46470.547,46462.742,46456.812,46431.207,46410.03,46367.082,46377.195,46303.957,46298.938,46294.24,46287.87,46365.89,46404.887,46391.438,46381.074,46380.164,46378.234,46366.54,46365.555,46359.094,46330.082,46324.76,46267.117,46410.895,46287.64,46243.03,46219.176,46167.01,46136.773,46165.473,46102.96,46085.87,46121.76,46105.555,46097.965,46126.836,46183.316,46178.543,46160.39,46153.86,46154.89,46152.86,46155.062,46147.164,46136.85,46196.88,46248.766,46192.203,46140.49,46152.29,46156.406,46190.402,46177.043,46162.75,46174.207,46205.09,46206.227,46223.27,46219.383,46213.715,46206.145,46205.36,46205.184,46204.91,46205.22,46206.617,46204.645,46205.88,46199.31,46195.81,46203.37,46156.86,46261.47,46399.523,46402.223,46423.44,46425.723,46379.973,46362.84,46374.44,46352.45,46323.355,46303.723,46352.957,46351.723,46354.21,46344.805,46345.72,46342.15,46341.266,46337.754,46338.766,46318.84,46327.047,46391.234,46373.56,46321.562,46468.56,46500.57,46510.652,46511.406,46454.1,46511.258,46594.465,46595.125,46563.895,46564.082,46578.305,46584.625,46580.293,46578.062,46577.01,46575.617,46573.01,46574.29,46581.734,46624.805,46664.74,46673.926,46704.27,46714.453,46723.867,46721.25,46655.008,46617.22,46625.348,46641.973,46678.953,46637.527,46614.316,46618.918,46641.137,46648.824,46639.094,46642.805,46643.16,46643.266,46643.203,46635.72,46632.996,46635.42,46626.297,46621.406,46533.93,46545.5,46565.53,46596.707,46604.75,46626.28,46660.332,46679.895,46695.156,46709.52,46686.22,46682.906,46673.867,46671.535,46673.992,46685.637,46686.156,46688.824,46702.086,46694.74,46697.742,46701.51,46707.44,46735.668,46786.074,46796.8,46739.91,46769.273,46787.53,46838.363,46836.074,46952.598,47017.945,47001.79,47129.12,47167.473,47207.082,47225.89,47192.37,47184.797,47169.26,47160.582,47161.516,47171.938,47163.805,47179.66,47198.617,47174.676,47165.375,47302.24,47330.723,47374.793,47336.914,47277.22,47279.15,47223.9,47173.652,47192.605,47164.234,47152.465,47155.805,47153.4,47151.297,47151.816,47151.59,47151.25,47150.215,47151.543,47142.508,47135.14,47135.86,47158.42,47043.66,47005.97,46950.8,46969.95,47001.33,46981.363,47013.867,47019.09,47035.266,47026.234,47024.7,47022.6,47025.3,47026.12,47037.457,47045.74,47045.484,47046.938,47050.66,47052.88,47054.203,47054.848,47039.805,46943.96,47001.992,47103.63,47126.957,47119.7,47099.004,47098.367,47104.89,47121.97,47207.7,47201.09,47202.45,47195.6,47212.797,47214.93,47214.043,47210.086,47213.117,47208.76,47207.684,47205.164,47205.984,47207.86,47212.47,47243.33,47297.484,47276.664,47347.293,47370.867,47329.383,47468.184,47559.535,47498.48,47465.16,47427.164,47442.395,47434.69,47446.965,47450.4,47451.29,47450.805,47451.41,47450.582,47442.984,47440.945,47440.78,47432.54,47470.21,47520.906,47499.31,47428.418,47453.484,47446.113,47441.234,47430.613,47461.734,47444.43,47442.504,47448.004],\"type\":\"scatter\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"Test Actual\",\"x\":[658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731],\"y\":[47354.723,47386.867,47480.477,47473.496,47487.812,47481.54,47479.62,47470.945,47472.492,47478.9,47458.195,47448.29,47460.25,47502.414,47531.24,47498.434,47501.688,47516.1,47485.664,47526.723,47534.07,47558.37,47580.25,47563.18,47553.977,47579.523,47578.06,47567.715,47581.76,47578.43,47569.055,47570.44,47555.64,47533.176,47540.406,47546.89,47586.316,47688.715,47680.273,47713.484,47752.676,47771.42,47776.61,47787.48,47793.324,47894.84,47900.336,47876.62,47871.887,47895.88,47923.523,47921.543,47915.22,47883.438,47889.65,47888.965,47884.215,47877.965,47851.34,47849.41,47919.895,48024.168,48001.297,47956.777,47951.668,47942.934,47936.01,47891.285,47869.402,47898.98,47915.797,47921.13,47899.66,47902.406],\"type\":\"scatter\"},{\"line\":{\"color\":\"orange\",\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Test Pred\",\"x\":[658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731],\"y\":[47483.227,47386.242,47418.324,47508.484,47501.95,47515.332,47509.53,47507.8,47499.7,47501.184,47507.227,47487.766,47478.363,47489.84,47529.258,47555.53,47525.598,47528.598,47541.83,47513.8,47551.527,47558.176,47579.906,47599.184,47584.293,47576.22,47598.746,47597.484,47588.46,47600.8,47597.94,47589.793,47591.055,47578.01,47557.918,47564.414,47570.21,47604.9,47690.04,47683.297,47709.617,47739.652,47753.676,47757.59,47765.64,47770.004,47841.027,47844.855,47828.367,47825.316,47841.832,47860.83,47859.473,47855.164,47833.395,47837.71,47837.285,47834.055,47829.848,47811.87,47810.566,47858.496,47925.254,47911.188,47883.004,47879.652,47873.86,47869.22,47838.938,47824.203,47844.21,47855.656,47859.31,47844.69],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"color\":\"black\",\"dash\":\"dot\",\"width\":2},\"type\":\"line\",\"x0\":657.5,\"x1\":657.5,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}],\"legend\":{\"x\":0,\"y\":1},\"title\":{\"text\":\"Gold Price Forecast\"},\"xaxis\":{\"title\":{\"text\":\"Sample Index (time ordered)\"}},\"yaxis\":{\"title\":{\"text\":\"Price\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4f2dea95-f10d-4801-b46a-d1cd50920153');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'MAE': np.float32(25.052551),\n",
              "  'RMSE': np.float32(38.185543),\n",
              "  'MAPE': np.float32(0.05383903),\n",
              "  'sMAPE': np.float32(0.0538375),\n",
              "  'R2': np.float32(0.99089724),\n",
              "  'MASE': np.float32(1.1007028)},\n",
              " 'test': {'MAE': np.float32(41.446842),\n",
              "  'RMSE': np.float32(51.36988),\n",
              "  'MAPE': np.float32(0.0867803),\n",
              "  'sMAPE': np.float32(0.086811945),\n",
              "  'R2': np.float32(0.92784923),\n",
              "  'MASE': np.float32(1.8209983)}}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# you already have: trainset, testset, model\n",
        "# Create the same model architecture\n",
        "\n",
        "\n",
        "model = TransformerTS(\n",
        "    input_size=input_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    output_size=output_size,\n",
        "    dropout=dropout)\n",
        "\n",
        "# model = LSTM(input_size, num_hidden_layers, num_stacked_layers, output_size)\n",
        "\n",
        "# Load the saved weights\n",
        "model.load_state_dict(torch.load('/content/checkpoint_transformer.pt'))\n",
        "\n",
        "result = predict_train_test(model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "\n",
        "plot_predictions_plotly(result, horizon_step=0, title=\"Gold Price Forecast\")\n",
        "\n",
        "\n",
        "transformer_metrics = evaluate_forecast(result)\n",
        "transformer_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tKLh7-2SFu0K",
        "outputId": "2db2446d-1d20-45de-940c-20d0a09f0227"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"210e192b-f376-4ff8-b08e-33a919013c13\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"210e192b-f376-4ff8-b08e-33a919013c13\")) {                    Plotly.newPlot(                        \"210e192b-f376-4ff8-b08e-33a919013c13\",                        [{\"line\":{\"color\":\"black\"},\"mode\":\"lines\",\"name\":\"Test Actual\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73],\"y\":[47354.723,47386.867,47480.477,47473.496,47487.812,47481.54,47479.62,47470.945,47472.492,47478.9,47458.195,47448.29,47460.25,47502.414,47531.24,47498.434,47501.688,47516.1,47485.664,47526.723,47534.07,47558.37,47580.25,47563.18,47553.977,47579.523,47578.06,47567.715,47581.76,47578.43,47569.055,47570.44,47555.64,47533.176,47540.406,47546.89,47586.316,47688.715,47680.273,47713.484,47752.676,47771.42,47776.61,47787.48,47793.324,47894.84,47900.336,47876.62,47871.887,47895.88,47923.523,47921.543,47915.22,47883.438,47889.65,47888.965,47884.215,47877.965,47851.34,47849.41,47919.895,48024.168,48001.297,47956.777,47951.668,47942.934,47936.01,47891.285,47869.402,47898.98,47915.797,47921.13,47899.66,47902.406],\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"LSTM Pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73],\"y\":[47454.664,47391.64,47401.434,47466.3,47475.887,47488.35,47488.13,47487.375,47481.816,47481.58,47485.664,47473.06,47463.45,47468.98,47497.453,47522.555,47508.824,47508.074,47517.15,47500.113,47521.977,47531.977,47549.74,47568.06,47563.48,47557.3,47571.125,47574.074,47569.023,47576.188,47576.258,47570.87,47570.27,47561.168,47544.867,47544.594,47548.027,47572.363,47636.94,47651.625,47675.117,47703.562,47722.895,47732.863,47742.414,47749.16,47798.156,47817.734,47815.906,47814.367,47824.484,47839.81,47844.965,47844.855,47832.145,47830.203,47829.02,47826.453,47822.71,47809.793,47804.06,47831.6,47881.805,47891.94,47880.39,47874.836,47869.5,47864.707,47844.83,47827.957,47833.46,47841.72,47846.703,47839.855],\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"GRU Pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73],\"y\":[47445.223,47380.72,47386.25,47456.91,47470.54,47480.875,47478.19,47475.43,47468.668,47468.03,47472.562,47459.51,47449.023,47455.176,47486.2,47513.348,47497.176,47493.87,47503.055,47485.016,47507.594,47519.01,47537.082,47555.293,47548.312,47539.734,47554.004,47557.074,47550.8,47557.977,47557.895,47551.645,47550.87,47541.324,47524.184,47524.816,47529.926,47556.734,47625.832,47637.887,47658.098,47684.64,47701.12,47707.453,47714.41,47719.094,47771.59,47788.035,47779.88,47774.863,47785.285,47801.336,47804.543,47802.117,47786.008,47784.715,47784.316,47781.965,47778.297,47764.082,47759.383,47792.844,47848.61,47853.38,47833.938,47826.047,47820.09,47815.414,47792.977,47776.27,47786.676,47797.902,47803.355,47794.383],\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Transformer Pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73],\"y\":[47483.227,47386.242,47418.324,47508.484,47501.95,47515.332,47509.53,47507.8,47499.7,47501.184,47507.227,47487.766,47478.363,47489.84,47529.258,47555.53,47525.598,47528.598,47541.83,47513.8,47551.527,47558.176,47579.906,47599.184,47584.293,47576.22,47598.746,47597.484,47588.46,47600.8,47597.94,47589.793,47591.055,47578.01,47557.918,47564.414,47570.21,47604.9,47690.04,47683.297,47709.617,47739.652,47753.676,47757.59,47765.64,47770.004,47841.027,47844.855,47828.367,47825.316,47841.832,47860.83,47859.473,47855.164,47833.395,47837.71,47837.285,47834.055,47829.848,47811.87,47810.566,47858.496,47925.254,47911.188,47883.004,47879.652,47873.86,47869.22,47838.938,47824.203,47844.21,47855.656,47859.31,47844.69],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"legend\":{\"x\":0,\"y\":1},\"title\":{\"text\":\"Gold Price Forecasts (Test)\"},\"xaxis\":{\"title\":{\"text\":\"Test Sample Index (time ordered)\"}},\"yaxis\":{\"title\":{\"text\":\"Price\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('210e192b-f376-4ff8-b08e-33a919013c13');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot results of models on testset\n",
        "lstm_test_pred_inv = predict_train_test(lstm_model, trainset, testset, batch_size=128, scaler=scaler)['test_pred_inv']\n",
        "gru_test_pred_inv = predict_train_test(gru_model, trainset, testset, batch_size=128, scaler=scaler)['test_pred_inv']\n",
        "transformer_test_pred_inv = predict_train_test(model, trainset, testset, batch_size=128, scaler=scaler)['test_pred_inv']\n",
        "test_true_inv = predict_train_test(model, trainset, testset, batch_size=128, scaler=scaler)['test_true_inv']\n",
        "\n",
        "\n",
        "results = {\n",
        "    \"test_true_inv\": test_true_inv,           # shape [N] or [N, H]\n",
        "    \"preds\": {\n",
        "        \"LSTM\": lstm_test_pred_inv,           # shape [N] or [N, H]\n",
        "        \"GRU\": gru_test_pred_inv,\n",
        "        \"Transformer\": transformer_test_pred_inv\n",
        "    }\n",
        "}\n",
        "\n",
        "plot_test_predictions_plotly(results, horizon_step=0, title=\"Gold Price Forecasts (Test)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbgSeOvA8Knn"
      },
      "source": [
        "## Grid Search (Params Optimization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s0nKb1M8PX2"
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "\n",
        "param_grid = {\n",
        "    'd_model': [64, 256],\n",
        "    'lr': [0.001, 0.01],\n",
        "    'nhead': [8, 16],\n",
        "    'num_encoder_layers': [1, 6],\n",
        "    'dim_feedforward':[64, 256],\n",
        "    'dropout': [0.1, 0.5]\n",
        "\n",
        "}\n",
        "\n",
        "keys = param_grid.keys()\n",
        "\n",
        "combinations = [dict(zip(keys, values)) for values in product(*param_grid.values())]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT2tW6lh-N-q"
      },
      "outputs": [],
      "source": [
        "augmentations = Compose([AddGaussianNoise(), RandomScaling()])\n",
        "\n",
        "trainset, train_loader, testset, test_loader = get_loaders(df, time_bin=60, scaler=scaler, lookback=6,\n",
        "                                        lookforward=1, batch_size=16, train_size=0.9,\n",
        "                                        transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0LNDPU2X-iJJ",
        "outputId": "8ade23da-b59f-45ca-afff-66e07026ea1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 1] Early stopping at epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 2] Early stopping at epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 3] Early stopping at epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 4] Early stopping at epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 5] Early stopping at epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 6] Early stopping at epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 7] Early stopping at epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 8] Early stopping at epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 9] Early stopping at epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 10] Early stopping at epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 11] Early stopping at epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 12] Early stopping at epoch 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 13] Early stopping at epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 14] Early stopping at epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 15] Early stopping at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 16] Early stopping at epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 17] Early stopping at epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 18] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 19] Early stopping at epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 20] Early stopping at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 21] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 22] Early stopping at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 23] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 24] Early stopping at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 25] Early stopping at epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 26] Early stopping at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 27] Early stopping at epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 28] Early stopping at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 29] Early stopping at epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 30] Early stopping at epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 31] Early stopping at epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 32] Early stopping at epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 33] Early stopping at epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 34] Early stopping at epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 35] Early stopping at epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 36] Early stopping at epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 37] Early stopping at epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 38] Early stopping at epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 39] Early stopping at epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 40] Early stopping at epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 41] Early stopping at epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 42] Early stopping at epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 43] Early stopping at epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 44] Early stopping at epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 45] Early stopping at epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 46] Early stopping at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 47] Early stopping at epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 48] Early stopping at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 49] Early stopping at epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 50] Early stopping at epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 51] Early stopping at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 52] Early stopping at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 53] Early stopping at epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 54] Early stopping at epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 55] Early stopping at epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 56] Early stopping at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 57] Early stopping at epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 58] Early stopping at epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 59] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 60] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 61] Early stopping at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 62] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 63] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG 64] Early stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   d_model     lr  nhead  num_encoder_layers  dim_feedforward  dropout  \\\n",
              "0      256  0.001      8                   1              256      0.1   \n",
              "1      256  0.001     16                   1               64      0.1   \n",
              "2       64  0.010      8                   1               64      0.1   \n",
              "3      256  0.001      8                   1               64      0.1   \n",
              "4      256  0.001      8                   1              256      0.5   \n",
              "\n",
              "    train_MAE  train_RMSE  train_MAPE  train_sMAPE  train_R2  train_MASE  \\\n",
              "0   59.876881  311.896606    0.134548     0.131579  0.635762    1.277514   \n",
              "1  104.224777  318.076447    0.230257     0.227805  0.621185    2.223706   \n",
              "2   47.454025  307.333282    0.107617     0.104765  0.646342    1.012464   \n",
              "3  106.763321  324.294800    0.235487     0.232300  0.606228    2.277868   \n",
              "4  156.878799  349.178284    0.343728     0.340185  0.543481    3.347116   \n",
              "\n",
              "    test_MAE  test_RMSE  test_MAPE  test_sMAPE   test_R2  test_MASE  \n",
              "0  28.325327  38.131069   0.059378    0.059385  0.960992   0.604340  \n",
              "1  30.906672  38.924900   0.064777    0.064772  0.959350   0.659415  \n",
              "2  30.021906  41.927132   0.062885    0.062913  0.952838   0.640538  \n",
              "3  36.672825  45.775204   0.076973    0.076952  0.943784   0.782440  \n",
              "4  37.275181  46.248051   0.078194    0.078180  0.942616   0.795291  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec1bb963-416d-44e0-a227-27b0d5bcbf58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d_model</th>\n",
              "      <th>lr</th>\n",
              "      <th>nhead</th>\n",
              "      <th>num_encoder_layers</th>\n",
              "      <th>dim_feedforward</th>\n",
              "      <th>dropout</th>\n",
              "      <th>train_MAE</th>\n",
              "      <th>train_RMSE</th>\n",
              "      <th>train_MAPE</th>\n",
              "      <th>train_sMAPE</th>\n",
              "      <th>train_R2</th>\n",
              "      <th>train_MASE</th>\n",
              "      <th>test_MAE</th>\n",
              "      <th>test_RMSE</th>\n",
              "      <th>test_MAPE</th>\n",
              "      <th>test_sMAPE</th>\n",
              "      <th>test_R2</th>\n",
              "      <th>test_MASE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>59.876881</td>\n",
              "      <td>311.896606</td>\n",
              "      <td>0.134548</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>0.635762</td>\n",
              "      <td>1.277514</td>\n",
              "      <td>28.325327</td>\n",
              "      <td>38.131069</td>\n",
              "      <td>0.059378</td>\n",
              "      <td>0.059385</td>\n",
              "      <td>0.960992</td>\n",
              "      <td>0.604340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>104.224777</td>\n",
              "      <td>318.076447</td>\n",
              "      <td>0.230257</td>\n",
              "      <td>0.227805</td>\n",
              "      <td>0.621185</td>\n",
              "      <td>2.223706</td>\n",
              "      <td>30.906672</td>\n",
              "      <td>38.924900</td>\n",
              "      <td>0.064777</td>\n",
              "      <td>0.064772</td>\n",
              "      <td>0.959350</td>\n",
              "      <td>0.659415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64</td>\n",
              "      <td>0.010</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>47.454025</td>\n",
              "      <td>307.333282</td>\n",
              "      <td>0.107617</td>\n",
              "      <td>0.104765</td>\n",
              "      <td>0.646342</td>\n",
              "      <td>1.012464</td>\n",
              "      <td>30.021906</td>\n",
              "      <td>41.927132</td>\n",
              "      <td>0.062885</td>\n",
              "      <td>0.062913</td>\n",
              "      <td>0.952838</td>\n",
              "      <td>0.640538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>106.763321</td>\n",
              "      <td>324.294800</td>\n",
              "      <td>0.235487</td>\n",
              "      <td>0.232300</td>\n",
              "      <td>0.606228</td>\n",
              "      <td>2.277868</td>\n",
              "      <td>36.672825</td>\n",
              "      <td>45.775204</td>\n",
              "      <td>0.076973</td>\n",
              "      <td>0.076952</td>\n",
              "      <td>0.943784</td>\n",
              "      <td>0.782440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5</td>\n",
              "      <td>156.878799</td>\n",
              "      <td>349.178284</td>\n",
              "      <td>0.343728</td>\n",
              "      <td>0.340185</td>\n",
              "      <td>0.543481</td>\n",
              "      <td>3.347116</td>\n",
              "      <td>37.275181</td>\n",
              "      <td>46.248051</td>\n",
              "      <td>0.078194</td>\n",
              "      <td>0.078180</td>\n",
              "      <td>0.942616</td>\n",
              "      <td>0.795291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec1bb963-416d-44e0-a227-27b0d5bcbf58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec1bb963-416d-44e0-a227-27b0d5bcbf58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec1bb963-416d-44e0-a227-27b0d5bcbf58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de38aaf9-2bb0-4547-9786-ed1dc501e5a1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de38aaf9-2bb0-4547-9786-ed1dc501e5a1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de38aaf9-2bb0-4547-9786-ed1dc501e5a1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_grid",
              "summary": "{\n  \"name\": \"df_grid\",\n  \"rows\": 64,\n  \"fields\": [\n    {\n      \"column\": \"d_model\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          64,\n          256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004535573676110723,\n        \"min\": 0.001,\n        \"max\": 0.01,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.01,\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nhead\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 8,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_encoder_layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dim_feedforward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          64,\n          256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dropout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20158105227158793,\n        \"min\": 0.1,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_MAE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          614.7304077148438,\n          451.2472839355469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_RMSE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          760.3920288085938,\n          598.1897583007812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_MAPE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          1.3335003852844238,\n          0.9788501858711243\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_sMAPE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          1.3195170164108276,\n          0.9711848497390747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_R2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          -1.1649088859558105,\n          -0.3398076295852661\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_MASE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          13.115689277648926,\n          9.627666473388672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_MAE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          632.9443969726562,\n          893.9075927734375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_RMSE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          661.4508056640625,\n          914.5366821289062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_MAPE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          1.325530767440796,\n          1.8727104663848877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_sMAPE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          1.3351795673370361,\n          1.8912229537963867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_R2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          -10.738036155700684,\n          -21.43895149230957\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_MASE\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          13.504297256469727,\n          19.072124481201172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "num_epochs = 200\n",
        "results = []\n",
        "\n",
        "for cfg_idx, config in enumerate(combinations, start=1):\n",
        "\n",
        "  model = TransformerTS(\n",
        "      input_size=1,\n",
        "      d_model=config['d_model'],\n",
        "      nhead=config['nhead'],\n",
        "      num_encoder_layers=config['num_encoder_layers'],\n",
        "      dim_feedforward=config['dim_feedforward'],\n",
        "      output_size=1,\n",
        "      dropout=config['dropout'])\n",
        "\n",
        "  model.to(device)\n",
        "  loss_function = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
        "  early_stopping = EarlyStopping(patience=10, mode='min', verbose=False, save_path= f'/content/checkpoint_{cfg_idx}.pt')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      train_one_epoch(model, show=False)\n",
        "      stop_criteria = validate_one_epoch(model, show=False, early_stopping=early_stopping)\n",
        "\n",
        "      if stop_criteria:\n",
        "          print(f\"[CFG {cfg_idx}] Early stopping at epoch {epoch}\")\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "  model = TransformerTS(\n",
        "      input_size=1,\n",
        "      d_model=config['d_model'],\n",
        "      nhead=config['nhead'],\n",
        "      num_encoder_layers=config['num_encoder_layers'],\n",
        "      dim_feedforward=config['dim_feedforward'],\n",
        "      output_size=1,\n",
        "      dropout=config['dropout'])\n",
        "\n",
        "  model.load_state_dict(torch.load(f'/content/checkpoint_{cfg_idx}.pt'))\n",
        "\n",
        "  result = predict_train_test(model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "  transformer_metrics = evaluate_forecast(result)\n",
        "\n",
        "\n",
        "  #  train\n",
        "  for k, v in transformer_metrics['train'].items():\n",
        "      config[f\"train_{k}\"] = v\n",
        "\n",
        "  #  test\n",
        "  for k, v in transformer_metrics['test'].items():\n",
        "      config[f\"test_{k}\"] = v\n",
        "\n",
        "  results.append(config)\n",
        "\n",
        "df_grid = pd.DataFrame(results)\n",
        "\n",
        "if \"test_RMSE\" in df_grid.columns:\n",
        "    df_grid = df_grid.sort_values(by=\"test_RMSE\").reset_index(drop=True)\n",
        "\n",
        "\n",
        "df_grid.to_csv(\"transformer_grid_results.csv\", index=False)\n",
        "df_grid.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GtgFQkzQd8G"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8g_ilnxFzZh"
      },
      "source": [
        "\n",
        "*   Multiple step prediction\n",
        "*   How much Lookback\n",
        "*   Effect of TimeBin\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple step prediction"
      ],
      "metadata": {
        "id": "pR3teEB87jr2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WzAgIG6F33q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855bb28b-7fad-4b56-bccf-82287be7521b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning:\n",
            "\n",
            "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.05561\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.05150\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.02522\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.02186\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00452\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00149\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00246\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00101\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00127\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00151\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00088\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00143\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00069\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00132\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00076\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00084\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00062\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00310\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00143\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00190\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00155\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00189\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00059\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00395\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00080\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00386\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00116\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00153\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00324\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00269\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00208\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00174\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00135\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00170\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00237\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00048\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00176\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00545\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00066\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00219\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00045\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00037\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00047\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00066\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00207\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00149\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00069\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00076\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00144\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00306\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00113\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00111\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00053\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00277\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00042\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00347\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00050\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00053\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00410\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00102\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00224\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00155\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00059\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00225\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00164\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00215\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00165\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00036\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00039\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00158\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00130\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00116\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00130\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00088\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00065\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00060\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00057\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00070\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00114\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00052\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00030\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00212\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00028\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00044\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00067\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00074\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00093\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00242\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00039\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00053\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00113\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00035\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00076\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00078\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00112\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00092\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00041\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00213\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00053\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00286\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00152\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00040\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00124\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00054\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00108\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00378\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00057\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00137\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00043\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00042\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00197\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00038\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00139\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00131\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00126\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00508\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00065\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00066\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00034\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00135\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00242\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00236\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00029\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00058\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00032\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00044\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00037\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00321\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00037\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00030\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00042\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00040\n",
            "***************************************************\n",
            "\n",
            "Val Loss: 0.00095\n",
            "***************************************************\n",
            "\n",
            "Early stopping triggered\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(patience=50, mode='min', verbose=False, save_path='/content/checkpoint_lookforward.pt')\n",
        "\n",
        "\n",
        "trainset, train_loader, testset, test_loader = get_loaders(df, time_bin=60, scaler=scaler, lookback=6,\n",
        "                                        lookforward=10, batch_size=16, train_size=0.9,\n",
        "                                        transform=augmentations)\n",
        "model_lookforward = TransformerTS(\n",
        "    input_size=input_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    output_size= 10,\n",
        "    dropout=dropout)\n",
        "\n",
        "# model = GRUModel(1, 4, 1, 1)\n",
        "model_lookforward.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_lookforward.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model_lookforward, show=False)\n",
        "    stop_criteria = validate_one_epoch(model_lookforward, early_stopping)\n",
        "\n",
        "    if stop_criteria:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, sample_mean=3, lookahead_steps=3):\n",
        "        \"\"\"\n",
        "        Baseline model to predict `lookahead_steps` using the mean of the previous `sample_mean` time steps.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.sample_mean = sample_mean\n",
        "        self.lookahead_steps = lookahead_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: input of shape [batch_size, time_steps, features]\n",
        "        :return: predictions of shape [batch_size, lookahead_steps, features]\n",
        "        \"\"\"\n",
        "        # Get the last `sample_mean` number of time steps\n",
        "        last_samples = x[:, -self.sample_mean:, :]  # shape: [batch, sample_mean, features]\n",
        "\n",
        "        # Calculate the mean over the last `sample_mean` steps\n",
        "        mean_value = last_samples.mean(dim=1)  # shape: [batch, features]\n",
        "\n",
        "        # Repeat the mean value to generate predictions for the next `lookahead_steps`\n",
        "        repeated_predictions = mean_value.unsqueeze(1).repeat(1, self.lookahead_steps, 1)\n",
        "\n",
        "        return repeated_predictions\n"
      ],
      "metadata": {
        "id": "opzt7LyEAqY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "baselineModel = BaselineModel(sample_mean=10, lookahead_steps=10)\n",
        "\n",
        "\n",
        "model_lookforward.eval()\n",
        "all_predictions = []\n",
        "all_predictions_baseline = []\n",
        "all_actual_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(test_loader):  # test_loader should provide the test data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        predicted_baseline = baselineModel(inputs)\n",
        "        predicted = model_lookforward(inputs)  # predicted shape (batch_size, 3)\n",
        "        all_predictions_baseline.append(predicted_baseline.cpu().numpy())\n",
        "        all_predictions.append(predicted.cpu().numpy())\n",
        "        all_actual_values.append(labels.cpu().numpy())\n",
        "\n",
        "# Convert the list of predictions and labels to numpy arrays for easier plotting\n",
        "all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "all_actual_values = np.concatenate(all_actual_values, axis=0)\n",
        "all_predictions_baseline = np.concatenate(all_predictions_baseline, axis=0)\n",
        "\n",
        "\n",
        "print(mean_absolute_error(all_actual_values, all_predictions),\n",
        "mean_absolute_error(all_actual_values, all_predictions_baseline.squeeze(-1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc57iHEF7zJq",
        "outputId": "89b1397c-1250-49fc-9a05-e715dc02e5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.024832408875226974 0.013545608147978783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the BaselineModel\n",
        "baseline_model = BaselineModel(sample_mean=3, lookahead_steps=3)\n",
        "\n",
        "result = predict_train_test(baseline_model, trainset, testset, batch_size=128, scaler=scaler)\n",
        "\n",
        "baseline_metrics = evaluate_forecast(result)\n",
        "baseline_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KumMSy7s9Ry-",
        "outputId": "473c6ee1-2f33-467d-f155-e041b8b0ac41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'MAE': np.float32(60.92469),\n",
              "  'RMSE': np.float32(357.41925),\n",
              "  'MAPE': np.float32(0.13697843),\n",
              "  'sMAPE': np.float32(0.13486174),\n",
              "  'R2': np.float32(0.50790465),\n",
              "  'MASE': np.float32(1.053577)},\n",
              " 'test': {'MAE': np.float32(29.475332),\n",
              "  'RMSE': np.float32(41.677708),\n",
              "  'MAPE': np.float32(0.06180005),\n",
              "  'sMAPE': np.float32(0.0618294),\n",
              "  'R2': np.float32(0.95263547),\n",
              "  'MASE': np.float32(0.50971997)}}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NO2h3ZL_r4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}